{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport -jax\n",
    "%aimport -jaxlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza.envs as envs\n",
    "import stanza.policies as policies\n",
    "import optax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.random import PRNGKey\n",
    "from stanza import Partial\n",
    "from stanza.rl.ppo import PPO\n",
    "from stanza.train import Trainer\n",
    "from stanza.rl import EpisodicEnvironment, ACPolicy\n",
    "from stanza.rl.nets import MLPActorCritic\n",
    "from stanza.util.rich import StatisticsTable, ConsoleDisplay, LoopProgress\n",
    "from stanza.solver.ilqr import iLQRSolver\n",
    "from stanza.util.random import PRNGSequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanza.util.logging import logger\n",
    "from stanza.policies.mpc import MPC\n",
    "from stanza.data.trajectory import Timestep\n",
    "from stanza.data import Data\n",
    "env = envs.create(\"pendulum\")\n",
    "# will automatically reset when done\n",
    "# or when 1000 timesteps have been reached\n",
    "solver_t = iLQRSolver()\n",
    "expert_policy=MPC(\n",
    "            # Sample action\n",
    "            action_sample=env.sample_action(PRNGKey(42)),\n",
    "            cost_fn=env.cost, \n",
    "            model_fn=env.step,\n",
    "            horizon_length=50,\n",
    "            solver=solver_t,\n",
    "            receed=False\n",
    "        )\n",
    "\n",
    "def rollout_mpc(key: PRNGKey):\n",
    "    # An MPC policy\n",
    "    rollout = policies.rollout(\n",
    "        model=env.step,\n",
    "        state0=env.reset(key),\n",
    "        length=50,\n",
    "        policy=expert_policy\n",
    "    )\n",
    "    #turns from Python/jax Data class into Stanza Dataset\n",
    "    return Data.from_pytree(Timestep(rollout.states,rollout.actions))\n",
    "    \n",
    "    #logger.info(f'MPC Rollout with {solver} solver results')\n",
    "    #logger.info('states: {}', rollout.states)\n",
    "    #logger.info('actions: {}', rollout.actions)\n",
    "    #cost = env.cost(rollout.states, rollout.actions)\n",
    "    #logger.info('cost: {}', cost)\n",
    "\n",
    "\n",
    "num_trajs = 100\n",
    "def batch_roll(rng_key, num_t):\n",
    "    roll_fun = jax.vmap(rollout_mpc)\n",
    "    rng_keys = jax.random.split(rng_key,num_t)\n",
    "    return roll_fun(rng_keys)\n",
    "\n",
    "expert_data = Data.from_pytree(batch_roll(PRNGKey(42), num_trajs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCState(goal=StartEndGoal(start_state=None, end_state=State(angle=Array(3.1154735, dtype=float32), vel=Array(0.03439788, dtype=float32))), env_state=State(angle=Array(2.9252484, dtype=float32), vel=Array(0.22980095, dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "from stanza.goal_conditioned.roll_in_sampler import roll_in_sampler\n",
    "from stanza.envs import Environment\n",
    "from stanza.goal_conditioned import GCState, StartEndGoal\n",
    "import chex\n",
    "from stanza.data.trajectory import Timestep\n",
    "\n",
    "action_noiser = None\n",
    "process_noiser = None\n",
    "\n",
    "\n",
    "\n",
    "def gsa_sampler(key: PRNGKey, traj_data = expert_data,  env : Environment = env, encode_start = False, \n",
    "                delta_t_max = 3, delta_t_min = 8,\n",
    "                roll_len_min = 3, roll_len_max = 8):\n",
    "\n",
    "    \n",
    "    #chex.assert_scalar_non_negative(roll_len_min)\n",
    "\n",
    "    rng = PRNGSequence(key)\n",
    "    rand_traj = traj_data.sample(next(rng))\n",
    "    traj_len = rand_traj.length\n",
    "\n",
    "    delta_t = jax.random.randint(next(rng), (), minval = delta_t_min,maxval = delta_t_max)\n",
    "    delta_t = jax.lax.cond(delta_t <= traj_len - 1, lambda x: x, lambda x: traj_len - 1, operand = delta_t) \n",
    "\n",
    "    start_t = jax.random.randint(next(rng), (), minval = 1,\n",
    "                                 maxval = traj_len - delta_t)\n",
    "    \n",
    "    roll_len = jax.random.randint(next(rng), (), minval = roll_len_min,maxval = roll_len_max)\n",
    "    \n",
    "    roll_len = jax.lax.cond(roll_len < start_t + 1, lambda x: x, lambda x: start_t, operand = roll_len)\n",
    "    \n",
    "    \n",
    "\n",
    "    start_state, start_action =  roll_in_sampler(traj = rand_traj,\n",
    "                    target_time = start_t,\n",
    "                    noise_rng_key = next(rng), \n",
    "                    roll_len = roll_len, \n",
    "                    env = env, \n",
    "                    env_rng_key = next(rng),\n",
    "                    action_noiser = action_noiser, \n",
    "                    process_noiser = process_noiser )\n",
    "        \n",
    "    end_state = rand_traj.get(start_t + delta_t).observation\n",
    "\n",
    "    if encode_start:\n",
    "        goal = StartEndGoal(start_state = start_state, \n",
    "                            end_state = end_state)\n",
    "    else:\n",
    "        goal = StartEndGoal(start_state = None, end_state = end_state)\n",
    "    return Timestep(observation = GCState(goal = goal, env_state = start_state), \n",
    "                    action = start_action)\n",
    "\n",
    "gs_sampler = (lambda key: gsa_sampler(key, encode_start = False).observation)\n",
    "my_gc_state = gs_sampler(PRNGKey(42))\n",
    "print(my_gc_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def goal_reward(state, next_state, end_state):\n",
    "        angle_diff = next_state.angle - state.angle\n",
    "        vel_diff = next_state.vel - state.vel\n",
    "        angle_rew = 32 * angle_diff * jnp.sign(end_state.angle - next_state.angle)\n",
    "        vel_rew = vel_diff * jnp.sign(end_state.vel-next_state.vel)\n",
    "        return angle_rew + vel_rew\n",
    "\n",
    "def cost_to_goal( x, u, x_goal):\n",
    "        x = jnp.stack((x.angle, x.vel), -1)\n",
    "        x_goal = jnp.stack((x_goal.angle, x_goal.vel), -1)\n",
    "        diff = (x - x_goal)\n",
    "        x_cost = jnp.sum(diff[:-1]**2)\n",
    "        xf_cost = jnp.sum(diff[-1]**2)\n",
    "        if u == None:\n",
    "            u_cost = 0\n",
    "        else:\n",
    "            u_cost = jnp.sum(u**2)\n",
    "        return 5*xf_cost + 2*x_cost + u_cost\n",
    "\n",
    "def gc_reward(gc_state, action, next_state ):\n",
    "    env_state, goal = gc_state.env_state, gc_state.goal\n",
    "    end_state = goal.end_state\n",
    "    \n",
    "    return goal_reward(env_state,next_state,end_state)\n",
    "    #return 3 - (1 * cost_to_goal(env_state, action, end_state))\n",
    "\n",
    "def g_done(gc_state):\n",
    "        x = gc_state.env_state\n",
    "        x_goal = gc_state.goal.end_state\n",
    "        return (cost_to_goal(x =x,u=None,x_goal = x_goal) < .03*.03)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanza.goal_conditioned import GCEnvironment\n",
    "gc_pendulum_env = GCEnvironment(env = env, gs_sampler = gs_sampler,\n",
    "                            gc_reward = gc_reward, g_done = g_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy_made\n",
      "rolling out policy\n",
      "[ 1.5575948  -1.1119164   0.08042021  2.0939438 ]\n",
      "-3.0967412\n",
      "{'log_prob': Array([-2.1214223 , -1.5447118 , -0.92164135, -3.0967412 ], dtype=float32), 'value': Array([-0.00346179,  0.00905811, -0.00111795, -0.0009095 ], dtype=float32)}\n",
      "GCState(goal=StartEndGoal(start_state=None, end_state=State(angle=Array([3.1154735, 3.1154735, 3.1154735, 3.1154735, 3.1154735], dtype=float32), vel=Array([0.03439788, 0.03439788, 0.03439788, 0.03439788, 0.03439788],      dtype=float32))), env_state=State(angle=Array([2.9252484, 2.9712086, 3.0781543, 3.1388757, 3.2019532], dtype=float32), vel=Array([0.22980095, 0.5347287 , 0.3036069 , 0.31538695, 0.7309675 ],      dtype=float32)))\n",
      "rolling out bipo\n",
      "done rollout\n",
      "[ 1.5575948  -1.1119164   0.08042021  2.0939438 ]\n",
      "BLPolicyState(state_low_level=None, state_high_level=Array(-3.0967412, dtype=float32), chunk_time=Array(1, dtype=int32, weak_type=True), current_goal=Array(2.0939438, dtype=float32), info_high_level={'log_prob': Array(-3.0967412, dtype=float32), 'value': Array(-0.0009095, dtype=float32)})\n",
      "{'high': {'log_prob': Array([-2.1214223 , -1.5447118 , -0.92164135, -3.0967412 ], dtype=float32), 'value': Array([-0.00346179,  0.00905811, -0.00111795, -0.0009095 ], dtype=float32)}, 'low': {}}\n",
      "GCState(goal=StartEndGoal(start_state=None, end_state=State(angle=Array([3.1154735, 3.1154735, 3.1154735, 3.1154735, 3.1154735], dtype=float32), vel=Array([0.03439788, 0.03439788, 0.03439788, 0.03439788, 0.03439788],      dtype=float32))), env_state=State(angle=Array([2.9252484, 2.9712086, 3.0781543, 3.1388757, 3.2019532], dtype=float32), vel=Array([0.22980095, 0.5347287 , 0.3036069 , 0.31538695, 0.7309675 ],      dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "#Set up net and env\n",
    "ep_env = EpisodicEnvironment(gc_pendulum_env, 1000)\n",
    "from stanza.rl.nets import transform_ac_to_mean\n",
    "from stanza.goal_conditioned.bilevel_policy import make_trivial_bi_policy\n",
    "\n",
    "net = MLPActorCritic(\n",
    "    ep_env.sample_action(PRNGKey(0))\n",
    ")\n",
    "init_params = net.init(PRNGKey(42),\n",
    "    ep_env.observe(ep_env.sample_state(PRNGKey(0))))\n",
    "\n",
    "net.apply(init_params,gs_sampler(PRNGKey(0)))\n",
    "\n",
    "\n",
    "ac_apply = Partial(net.apply, init_params)\n",
    "policy = ACPolicy(ac_apply)\n",
    "bipo = make_trivial_bi_policy(policy)\n",
    "print(\"policy_made\")\n",
    "\n",
    "start_state = ep_env.reset(PRNGKey(42))\n",
    "m_key = PRNGKey(31231)\n",
    "p_key = PRNGKey(43232)\n",
    "print(\"rolling out policy\")\n",
    "roll_len = 5\n",
    "\n",
    "def print_roll_info(r):\n",
    "    print(r.actions)\n",
    "    print(r.final_policy_state)\n",
    "    print(r.info)\n",
    "    print(jax.vmap(ep_env.observe)(r.states))\n",
    "\n",
    "\n",
    "r = policies.rollout(ep_env.step, \n",
    "    start_state , policy, \n",
    "    model_rng_key=m_key,\n",
    "    policy_rng_key=p_key,\n",
    "    observe=ep_env.observe,\n",
    "    length=roll_len)\n",
    "print_roll_info(r)\n",
    "\n",
    "print(\"rolling out bipo\")\n",
    "r = policies.rollout(ep_env.step, \n",
    "    start_state , bipo, \n",
    "    model_rng_key=m_key,\n",
    "    policy_rng_key=p_key,\n",
    "    observe=ep_env.observe,\n",
    "    length=roll_len)\n",
    "print(\"done rollout\")\n",
    "print_roll_info(r)\n",
    "\n",
    "#net.apply(init_params, ep_env.sample_state(PRNGKey(0)))\n",
    "#actor_apply = transform_ac_to_mean(net.apply)\n",
    "#actor_apply(init_params,ep_env.sample_state(PRNGKey(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f8cb94bd7b408fb9d062853c38119d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:53:39] </span><span style=\"color: #008000; text-decoration-color: #008000\">TRACE </span> - <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;Tracing&gt;</span> Tracing batch loss                                                     <a href=\"file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py#43\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">43</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:53:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mTRACE \u001b[0m - \u001b[1;33m<\u001b[0m\u001b[1;33mTracing\u001b[0m\u001b[1;33m>\u001b[0m Tracing batch loss                                                     \u001b]8;id=951486;file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=149159;file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py#43\u001b\\\u001b[2m43\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">TRACE </span> - <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;Tracing&gt;</span> Tracing training                                                      <a href=\"file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mTRACE \u001b[0m - \u001b[1;33m<\u001b[0m\u001b[1;33mTracing\u001b[0m\u001b[1;33m>\u001b[0m Tracing training                                                      \u001b]8;id=401832;file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=461717;file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">TRACE </span> - <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;Tracing&gt;</span> Tracing epoch step                                                    <a href=\"file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py#102\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">102</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mTRACE \u001b[0m - \u001b[1;33m<\u001b[0m\u001b[1;33mTracing\u001b[0m\u001b[1;33m>\u001b[0m Tracing epoch step                                                    \u001b]8;id=399186;file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=44488;file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py#102\u001b\\\u001b[2m102\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">TRACE </span> - <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;Tracing&gt;</span> Tracing train step                                                     <a href=\"file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py#72\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">72</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mTRACE \u001b[0m - \u001b[1;33m<\u001b[0m\u001b[1;33mTracing\u001b[0m\u001b[1;33m>\u001b[0m Tracing train step                                                     \u001b]8;id=40025;file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=593326;file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py#72\u001b\\\u001b[2m72\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">TRACE </span> - <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;Tracing&gt;</span> Done tracing training                                                 <a href=\"file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py#132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">132</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mTRACE \u001b[0m - \u001b[1;33m<\u001b[0m\u001b[1;33mTracing\u001b[0m\u001b[1;33m>\u001b[0m Done tracing training                                                 \u001b]8;id=366711;file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=113537;file:///Users/msimchowitz1/Documents/code/stanza/stanza/train/__init__.py#132\u001b\\\u001b[2m132\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BC Pretraining    \n",
    "from stanza.rl.bc import BCState, BCTrainer\n",
    "\n",
    "\n",
    "rng_bc = PRNGKey(41)\n",
    "# note, use > 256 data_points!!\n",
    "num_bc_data = 500\n",
    "gc_data = jax.vmap(gsa_sampler)(jax.random.split(PRNGKey(40),num_bc_data))\n",
    "gc_data = Data.from_pytree(gc_data)\n",
    "actor_apply = transform_ac_to_mean(net.apply)\n",
    "\n",
    "\n",
    "display = ConsoleDisplay()\n",
    "display.add(\"train\", StatisticsTable(), interval=100)\n",
    "display.add(\"train\", LoopProgress(), interval=100)\n",
    "\n",
    "with display as w:\n",
    "    trainer = BCTrainer()\n",
    "    result =  trainer.train(ac_apply=actor_apply, \n",
    "                                ac_params = init_params, dataset=gc_data,\n",
    "                                rng_key = rng_bc,\n",
    "                                max_iterations=10000,\n",
    "                                 hooks=[w.train])\n",
    "new_params = result.fn_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mutable default <class 'list'> for field envs_list is not allowed: use default_factory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# RL Training \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstanza\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgoal_conditioned\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcurriculum\u001b[39;00m \u001b[39mimport\u001b[39;00m ppo_train\n\u001b[1;32m      4\u001b[0m display \u001b[39m=\u001b[39m ConsoleDisplay()\n\u001b[1;32m      5\u001b[0m display\u001b[39m.\u001b[39madd(\u001b[39m\"\u001b[39m\u001b[39mppo\u001b[39m\u001b[39m\"\u001b[39m, StatisticsTable(), interval\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/code/stanza/stanza/goal_conditioned/curriculum.py:18\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstanza\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrl\u001b[39;00m \u001b[39mimport\u001b[39;00m EpisodicEnvironment\n\u001b[1;32m     14\u001b[0m \u001b[39m# a mixture of environments\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# each sampled with a given probability\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m# for resets\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m# transitions \u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39m@dataclass\u001b[39;49m(jax\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     19\u001b[0m \u001b[39mclass\u001b[39;49;00m \u001b[39mMixtureEnvironment\u001b[39;49;00m(Environment):\n\u001b[1;32m     21\u001b[0m     envs_list : \u001b[39mlist\u001b[39;49m \u001b[39m=\u001b[39;49m []\n\u001b[1;32m     22\u001b[0m     probs_list : \u001b[39mlist\u001b[39;49m \u001b[39m=\u001b[39;49m []\n",
      "File \u001b[0;32m~/Documents/code/stanza/stanza/dataclasses/__init__.py:20\u001b[0m, in \u001b[0;36m_make_dataclass\u001b[0;34m(cls, jax, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_dataclass\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, jax\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 20\u001b[0m     dcls \u001b[39m=\u001b[39m _dataclass(\u001b[39mcls\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     21\u001b[0m     \u001b[39mif\u001b[39;00m jax:\n\u001b[1;32m     22\u001b[0m         \u001b[39mimport\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree_util\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/dataclasses.py:1223\u001b[0m, in \u001b[0;36mdataclass\u001b[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[39mreturn\u001b[39;00m wrap\n\u001b[1;32m   1222\u001b[0m \u001b[39m# We're called as @dataclass without parens.\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(\u001b[39mcls\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/dataclasses.py:1213\u001b[0m, in \u001b[0;36mdataclass.<locals>.wrap\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[0;32m-> 1213\u001b[0m     \u001b[39mreturn\u001b[39;00m _process_class(\u001b[39mcls\u001b[39;49m, init, \u001b[39mrepr\u001b[39;49m, eq, order, unsafe_hash,\n\u001b[1;32m   1214\u001b[0m                           frozen, match_args, kw_only, slots,\n\u001b[1;32m   1215\u001b[0m                           weakref_slot)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/dataclasses.py:958\u001b[0m, in \u001b[0;36m_process_class\u001b[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[0m\n\u001b[1;32m    955\u001b[0m         kw_only \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    956\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m         \u001b[39m# Otherwise it's a field of some type.\u001b[39;00m\n\u001b[0;32m--> 958\u001b[0m         cls_fields\u001b[39m.\u001b[39mappend(_get_field(\u001b[39mcls\u001b[39;49m, name, \u001b[39mtype\u001b[39;49m, kw_only))\n\u001b[1;32m    960\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m cls_fields:\n\u001b[1;32m    961\u001b[0m     fields[f\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m f\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/dataclasses.py:815\u001b[0m, in \u001b[0;36m_get_field\u001b[0;34m(cls, a_name, a_type, default_kw_only)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39m# For real fields, disallow mutable defaults.  Use unhashable as a proxy\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[39m# indicator for mutability.  Read the __hash__ attribute from the class,\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[39m# not the instance.\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39m_field_type \u001b[39mis\u001b[39;00m _FIELD \u001b[39mand\u001b[39;00m f\u001b[39m.\u001b[39mdefault\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__hash__\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmutable default \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(f\u001b[39m.\u001b[39mdefault)\u001b[39m}\u001b[39;00m\u001b[39m for field \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    816\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mf\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m is not allowed: use default_factory\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    818\u001b[0m \u001b[39mreturn\u001b[39;00m f\n",
      "\u001b[0;31mValueError\u001b[0m: mutable default <class 'list'> for field envs_list is not allowed: use default_factory"
     ]
    }
   ],
   "source": [
    "# RL Training \n",
    "\n",
    "display = ConsoleDisplay()\n",
    "display.add(\"ppo\", StatisticsTable(), interval=1)\n",
    "display.add(\"ppo\", LoopProgress(\"RL\"), interval=1)\n",
    "\n",
    "ppo = PPO(\n",
    "    trainer = Trainer(\n",
    "        optimizer=optax.chain(\n",
    "            optax.clip_by_global_norm(0.5),\n",
    "            optax.adam(3e-4, eps=1e-5)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "with display as dh:\n",
    "    trained_params = ppo.train(\n",
    "        PRNGKey(42),\n",
    "        ep_env, net.apply,\n",
    "        params = new_params,\n",
    "        rl_hooks=[dh.ppo]\n",
    "    )\n",
    "\n",
    "ac_apply = Partial(net.apply, trained_params.fn_params)\n",
    "policy = ACPolicy(ac_apply)\n",
    "\n",
    "r = policies.rollout(ep_env.step, \n",
    "    ep_env.reset(PRNGKey(42)), policy, \n",
    "    model_rng_key=PRNGKey(31231),\n",
    "    policy_rng_key=PRNGKey(43232),\n",
    "    observe=ep_env.observe,\n",
    "    length=200)\n",
    "\n",
    "print(jax.vmap(ep_env.observe)(r.states))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
