{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport -jax\n",
    "%aimport -jaxlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza.envs as envs\n",
    "import stanza.policies as policies\n",
    "\n",
    "import jax.flatten_util\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from jax.random import PRNGKey\n",
    "from stanza.util.random import PRNGSequence\n",
    "from stanza.util.logging import logger\n",
    "\n",
    "rng = PRNGSequence(42)\n",
    "env = envs.create(\"quadrotor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State(x=Array(-0.9451697, dtype=float32), z=Array(0.86506915, dtype=float32), phi=Array(0., dtype=float32), x_dot=Array(0., dtype=float32), z_dot=Array(0., dtype=float32), phi_dot=Array(0., dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(env.reset(next(rng)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first step: generate expert trajectories \n",
    "from stanza.policies.mpc import MPC\n",
    "from stanza.solver.ilqr import iLQRSolver\n",
    "my_horizon = 50\n",
    "solver_t = iLQRSolver()\n",
    "expert_policy=MPC(\n",
    "            # Sample action\n",
    "            action_sample=env.sample_action(PRNGKey(0)),\n",
    "            cost_fn=env.cost, \n",
    "            model_fn=env.step,\n",
    "            horizon_length=my_horizon,\n",
    "            solver=solver_t,\n",
    "            receed=False\n",
    "        )\n",
    "\n",
    "def rollout_policy(rng_key, my_pol):\n",
    "    # random init angle and angular velocity\n",
    "    x_0 = env.reset(rng_key) \n",
    "    roll = policies.rollout(model = env.step,\n",
    "                     state0 = x_0,\n",
    "                     policy = my_pol,\n",
    "                     length = my_horizon,\n",
    "                     last_state = False)\n",
    "    \n",
    "    return roll.states, roll.actions\n",
    "\n",
    "def batch_roll(rng_key, num_t, my_pol):\n",
    "    roll_fun = jax.vmap(rollout_policy,in_axes=(0,None))\n",
    "    rng_keys = jax.random.split(rng_key,num_t)\n",
    "    return roll_fun(rng_keys,my_pol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanza.data import Data\n",
    "expert_data = batch_roll(PRNGKey(42), 200,expert_policy)\n",
    "expert_data  = Data.from_pytree(expert_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanza.nets.mlp import MLP\n",
    "\n",
    "action_flat, action_uf = jax.flatten_util.ravel_pytree(env.sample_action(PRNGKey(0)))\n",
    "state_flat, state_uf = jax.flatten_util.ravel_pytree(env.sample_state(PRNGKey(0)))\n",
    "model = MLP([16, 16, 8,action_flat.shape[0]])\n",
    "\n",
    "def loss_fn(_,params,rng_key:PRNGKey, sample):\n",
    "    x,y = sample\n",
    "    y_flat, _ = jax.flatten_util.ravel_pytree(y)\n",
    "    x_flat, _ = jax.flatten_util.ravel_pytree(x)\n",
    "    a_flat = model.apply(params, x_flat)\n",
    "    loss = jnp.sum(jnp.square(y_flat-a_flat))\n",
    "    stats = {'loss': loss}\n",
    "    return None, loss, stats\n",
    "\n",
    "def model_policy(params, input):\n",
    "    x_flat, _ = jax.flatten_util.ravel_pytree(input.observation)\n",
    "    a_flat = model.apply(params, x_flat)\n",
    "    action = action_uf(a_flat)\n",
    "    return policies.PolicyOutput(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaxsimchowitz92\u001b[0m (\u001b[33mdpfrommer-projects\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msimchowitz1/Documents/code/stanza/notebooks/wandb/run-20230911_162308-xkp2ke15</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dpfrommer-projects/quadrotor_mlp/runs/xkp2ke15' target=\"_blank\">exalted-sponge-3</a></strong> to <a href='https://wandb.ai/dpfrommer-projects/quadrotor_mlp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dpfrommer-projects/quadrotor_mlp' target=\"_blank\">https://wandb.ai/dpfrommer-projects/quadrotor_mlp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dpfrommer-projects/quadrotor_mlp/runs/xkp2ke15' target=\"_blank\">https://wandb.ai/dpfrommer-projects/quadrotor_mlp/runs/xkp2ke15</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:23:09] </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">INFO  </span> - Logging to <span style=\"color: #000080; text-decoration-color: #000080\">exalted-sponge-</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">3</span>                                                     <a href=\"file:///var/folders/c4/13bl08593w34g7qzjvs_pbyc0000gp/T/ipykernel_47453/3449362941.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3449362941.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/c4/13bl08593w34g7qzjvs_pbyc0000gp/T/ipykernel_47453/3449362941.py#4\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:23:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[37mINFO  \u001b[0m - Logging to \u001b[34mexalted-sponge-\u001b[0m\u001b[1;34m3\u001b[0m                                                     \u001b]8;id=657826;file:///var/folders/c4/13bl08593w34g7qzjvs_pbyc0000gp/T/ipykernel_47453/3449362941.py\u001b\\\u001b[2m3449362941.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=382654;file:///var/folders/c4/13bl08593w34g7qzjvs_pbyc0000gp/T/ipykernel_47453/3449362941.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stanza.reporting.wandb import WandbDatabase\n",
    "\n",
    "db = WandbDatabase(\"dpfrommer-projects/quadrotor_mlp\").create()\n",
    "logger.info(f\"Logging to [blue]{db.name}[/blue]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanza.train import Trainer, batch_loss\n",
    "from stanza.train.validate import Validator\n",
    "from stanza.util.loop import every_kth_iteration, every_iteration, LoggerHook\n",
    "from stanza.util.rich import ConsoleDisplay, StatisticsTable, LoopProgress\n",
    "from stanza.reporting.jax import JaxDBScope\n",
    "\n",
    "import optax\n",
    "\n",
    "iterations = 10000\n",
    "optimizer = optax.adamw(optax.cosine_decay_schedule(1e-3, iterations), weight_decay=1e-4)\n",
    "\n",
    "\n",
    "print(\"creating console\")\n",
    "\n",
    "display = ConsoleDisplay()\n",
    "display.add(\"train\", StatisticsTable(), interval=100)\n",
    "display.add(\"train\", LoopProgress(), interval=100)\n",
    "\n",
    "\n",
    "print(\"creating scope\")\n",
    "\n",
    "#validator = Validator(next(rng), Data.from_pytree())\n",
    "\n",
    "dbs = JaxDBScope()\n",
    "\n",
    "print(\"training\")\n",
    "\n",
    "with display as display_handle, dbs as dbs_handle:\n",
    "    logger_hook = LoggerHook(every_kth_iteration(100))\n",
    "    db_logger_hook = dbs_handle.statistic_logging_hook(log_cond=every_kth_iteration(1), buffer=100)\n",
    "    trainer = Trainer(\n",
    "        loss_fn=batch_loss(loss_fn), batch_size=128,\n",
    "        optimizer=optimizer,\n",
    "        train_hooks=[db_logger_hook, logger_hook,\n",
    "                     display_handle.train]\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Initializing model...\")\n",
    "    init_params = model.init(next(rng), state_flat)\n",
    "    logger.info(\"Training...\")\n",
    "    params = trainer.train(expert_data, jit=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
