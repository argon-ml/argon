{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport -jax\n",
    "%aimport -jaxlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import chex\n",
    "import numpy as np\n",
    "from flax import struct\n",
    "from functools import partial\n",
    "from typing import Optional, Tuple, Union, Any\n",
    "from gymnax.environments import environment, spaces\n",
    "from brax import envs\n",
    "from brax.envs.wrappers.training import EpisodeWrapper, AutoResetWrapper\n",
    "\n",
    "class GymnaxWrapper(object):\n",
    "    \"\"\"Base class for Gymnax wrappers.\"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self._env = env\n",
    "\n",
    "    # provide proxy access to regular attributes of wrapped object\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._env, name)\n",
    "\n",
    "class FlattenObservationWrapper(GymnaxWrapper):\n",
    "    \"\"\"Flatten the observations of the environment.\"\"\"\n",
    "\n",
    "    def __init__(self, env: environment.Environment):\n",
    "        super().__init__(env)\n",
    "\n",
    "    def observation_space(self, params) -> spaces.Box:\n",
    "        assert isinstance(\n",
    "            self._env.observation_space(params), spaces.Box\n",
    "        ), \"Only Box spaces are supported for now.\"\n",
    "        return spaces.Box(\n",
    "            low=self._env.observation_space(params).low,\n",
    "            high=self._env.observation_space(params).high,\n",
    "            shape=(np.prod(self._env.observation_space(params).shape),),\n",
    "            dtype=self._env.observation_space(params).dtype,\n",
    "        )\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def reset(\n",
    "        self, key: chex.PRNGKey, params: Optional[environment.EnvParams] = None\n",
    "    ) -> Tuple[chex.Array, environment.EnvState]:\n",
    "        obs, state = self._env.reset(key, params)\n",
    "        obs = jnp.reshape(obs, (-1,))\n",
    "        return obs, state\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def step(\n",
    "        self,\n",
    "        key: chex.PRNGKey,\n",
    "        state: environment.EnvState,\n",
    "        action: Union[int, float],\n",
    "        params: Optional[environment.EnvParams] = None,\n",
    "    ) -> Tuple[chex.Array, environment.EnvState, float, bool, dict]:\n",
    "        obs, state, reward, done, info = self._env.step(key, state, action, params)\n",
    "        obs = jnp.reshape(obs, (-1,))\n",
    "        return obs, state, reward, done, info\n",
    "\n",
    "\n",
    "@struct.dataclass\n",
    "class LogEnvState:\n",
    "    env_state: environment.EnvState\n",
    "    episode_returns: float\n",
    "    episode_lengths: int\n",
    "    returned_episode_returns: float\n",
    "    returned_episode_lengths: int\n",
    "    timestep: int\n",
    "\n",
    "\n",
    "class LogWrapper(GymnaxWrapper):\n",
    "    \"\"\"Log the episode returns and lengths.\"\"\"\n",
    "\n",
    "    def __init__(self, env: environment.Environment):\n",
    "        super().__init__(env)\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def reset(\n",
    "        self, key: chex.PRNGKey, params: Optional[environment.EnvParams] = None\n",
    "    ) -> Tuple[chex.Array, environment.EnvState]:\n",
    "        obs, env_state = self._env.reset(key, params)\n",
    "        state = LogEnvState(env_state, 0, 0, 0, 0, 0)\n",
    "        return obs, state\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def step(\n",
    "        self,\n",
    "        key: chex.PRNGKey,\n",
    "        state: environment.EnvState,\n",
    "        action: Union[int, float],\n",
    "        params: Optional[environment.EnvParams] = None,\n",
    "    ) -> Tuple[chex.Array, environment.EnvState, float, bool, dict]:\n",
    "        obs, env_state, reward, done, info = self._env.step(\n",
    "            key, state.env_state, action, params\n",
    "        )\n",
    "        new_episode_return = state.episode_returns + reward\n",
    "        new_episode_length = state.episode_lengths + 1\n",
    "        state = LogEnvState(\n",
    "            env_state=env_state,\n",
    "            episode_returns=new_episode_return * (1 - done),\n",
    "            episode_lengths=new_episode_length * (1 - done),\n",
    "            returned_episode_returns=state.returned_episode_returns * (1 - done)\n",
    "            + new_episode_return * done,\n",
    "            returned_episode_lengths=state.returned_episode_lengths * (1 - done)\n",
    "            + new_episode_length * done,\n",
    "            timestep=state.timestep + 1,\n",
    "        )\n",
    "        info[\"returned_episode_returns\"] = state.returned_episode_returns\n",
    "        info[\"returned_episode_lengths\"] = state.returned_episode_lengths\n",
    "        info[\"timestep\"] = state.timestep\n",
    "        info[\"returned_episode\"] = done\n",
    "        return obs, state, reward, done, info\n",
    "\n",
    "\n",
    "class BraxGymnaxWrapper:\n",
    "    def __init__(self, env_name, backend=\"positional\"):\n",
    "        env = envs.get_environment(env_name=env_name, backend=backend)\n",
    "        env = EpisodeWrapper(env, episode_length=1000, action_repeat=1)\n",
    "        env = AutoResetWrapper(env)\n",
    "        self._env = env\n",
    "        self.action_size = env.action_size\n",
    "        self.observation_size = (env.observation_size,)\n",
    "\n",
    "    def reset(self, key, params=None):\n",
    "        state = self._env.reset(key)\n",
    "        return state.obs, state\n",
    "\n",
    "    def step(self, key, state, action, params=None):\n",
    "        next_state = self._env.step(state, action)\n",
    "        return next_state.obs, next_state, next_state.reward, next_state.done > 0.5, {}\n",
    "\n",
    "    def observation_space(self, params):\n",
    "        return spaces.Box(\n",
    "            low=-jnp.inf,\n",
    "            high=jnp.inf,\n",
    "            shape=(self._env.observation_size,),\n",
    "        )\n",
    "\n",
    "    def action_space(self, params):\n",
    "        return spaces.Box(\n",
    "            low=-1.0,\n",
    "            high=1.0,\n",
    "            shape=(self._env.action_size,),\n",
    "        )\n",
    "\n",
    "\n",
    "class ClipAction(GymnaxWrapper):\n",
    "    def __init__(self, env, low=-1.0, high=1.0):\n",
    "        super().__init__(env)\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "\n",
    "    def step(self, key, state, action, params=None):\n",
    "        \"\"\"TODO: In theory the below line should be the way to do this.\"\"\"\n",
    "        # action = jnp.clip(action, self.env.action_space.low, self.env.action_space.high)\n",
    "        action = jnp.clip(action, self.low, self.high)\n",
    "        return self._env.step(key, state, action, params)\n",
    "\n",
    "\n",
    "class TransformObservation(GymnaxWrapper):\n",
    "    def __init__(self, env, transform_obs):\n",
    "        super().__init__(env)\n",
    "        self.transform_obs = transform_obs\n",
    "\n",
    "    def reset(self, key, params=None):\n",
    "        obs, state = self._env.reset(key, params)\n",
    "        return self.transform_obs(obs), state\n",
    "\n",
    "    def step(self, key, state, action, params=None):\n",
    "        obs, state, reward, done, info = self._env.step(key, state, action, params)\n",
    "        return self.transform_obs(obs), state, reward, done, info\n",
    "\n",
    "class TransformReward(GymnaxWrapper):\n",
    "    def __init__(self, env, transform_reward):\n",
    "        super().__init__(env)\n",
    "        self.transform_reward = transform_reward\n",
    "\n",
    "    def step(self, key, state, action, params=None):\n",
    "        obs, state, reward, done, info = self._env.step(key, state, action, params)\n",
    "        return obs, state, self.transform_reward(reward), done, info\n",
    "\n",
    "\n",
    "class VecEnv(GymnaxWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.reset = jax.vmap(self._env.reset, in_axes=(0, None))\n",
    "        self.step = jax.vmap(self._env.step, in_axes=(0, 0, 0, None))\n",
    "\n",
    "\n",
    "@struct.dataclass\n",
    "class NormalizeVecObsEnvState:\n",
    "    mean: jnp.ndarray\n",
    "    var: jnp.ndarray\n",
    "    count: float\n",
    "    env_state: environment.EnvState\n",
    "\n",
    "\n",
    "class NormalizeVecObservation(GymnaxWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "    def reset(self, key, params=None):\n",
    "        obs, state = self._env.reset(key, params)\n",
    "        state = NormalizeVecObsEnvState(\n",
    "            mean=jnp.zeros_like(obs),\n",
    "            var=jnp.ones_like(obs),\n",
    "            count=1e-4,\n",
    "            env_state=state,\n",
    "        )\n",
    "        batch_mean = jnp.mean(obs, axis=0)\n",
    "        batch_var = jnp.var(obs, axis=0)\n",
    "        batch_count = obs.shape[0]\n",
    "\n",
    "        delta = batch_mean - state.mean\n",
    "        tot_count = state.count + batch_count\n",
    "\n",
    "        new_mean = state.mean + delta * batch_count / tot_count\n",
    "        m_a = state.var * state.count\n",
    "        m_b = batch_var * batch_count\n",
    "        M2 = m_a + m_b + jnp.square(delta) * state.count * batch_count / tot_count\n",
    "        new_var = M2 / tot_count\n",
    "        new_count = tot_count\n",
    "\n",
    "        state = NormalizeVecObsEnvState(\n",
    "            mean=new_mean,\n",
    "            var=new_var,\n",
    "            count=new_count,\n",
    "            env_state=state.env_state,\n",
    "        )\n",
    "\n",
    "        return (obs - state.mean) / jnp.sqrt(state.var + 1e-8), state\n",
    "\n",
    "    def step(self, key, state, action, params=None):\n",
    "        obs, env_state, reward, done, info = self._env.step(\n",
    "            key, state.env_state, action, params\n",
    "        )\n",
    "\n",
    "        batch_mean = jnp.mean(obs, axis=0)\n",
    "        batch_var = jnp.var(obs, axis=0)\n",
    "        batch_count = obs.shape[0]\n",
    "\n",
    "        delta = batch_mean - state.mean\n",
    "        tot_count = state.count + batch_count\n",
    "\n",
    "        new_mean = state.mean + delta * batch_count / tot_count\n",
    "        m_a = state.var * state.count\n",
    "        m_b = batch_var * batch_count\n",
    "        M2 = m_a + m_b + jnp.square(delta) * state.count * batch_count / tot_count\n",
    "        new_var = M2 / tot_count\n",
    "        new_count = tot_count\n",
    "\n",
    "        state = NormalizeVecObsEnvState(\n",
    "            mean=new_mean,\n",
    "            var=new_var,\n",
    "            count=new_count,\n",
    "            env_state=env_state,\n",
    "        )\n",
    "        return (\n",
    "            (obs - state.mean) / jnp.sqrt(state.var + 1e-8),\n",
    "            state,\n",
    "            reward,\n",
    "            done,\n",
    "            info,\n",
    "        )\n",
    "\n",
    "\n",
    "@struct.dataclass\n",
    "class NormalizeVecRewEnvState:\n",
    "    mean: jnp.ndarray\n",
    "    var: jnp.ndarray\n",
    "    count: float\n",
    "    return_val: float\n",
    "    env_state: environment.EnvState\n",
    "\n",
    "\n",
    "class NormalizeVecReward(GymnaxWrapper):\n",
    "    def __init__(self, env, gamma):\n",
    "        super().__init__(env)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def reset(self, key, params=None):\n",
    "        obs, state = self._env.reset(key, params)\n",
    "        batch_count = obs.shape[0]\n",
    "        state = NormalizeVecRewEnvState(\n",
    "            mean=0.0,\n",
    "            var=1.0,\n",
    "            count=1e-4,\n",
    "            return_val=jnp.zeros((batch_count,)),\n",
    "            env_state=state,\n",
    "        )\n",
    "        return obs, state\n",
    "\n",
    "    def step(self, key, state, action, params=None):\n",
    "        obs, env_state, reward, done, info = self._env.step(\n",
    "            key, state.env_state, action, params\n",
    "        )\n",
    "        return_val = state.return_val * self.gamma * (1 - done) + reward\n",
    "\n",
    "        batch_mean = jnp.mean(return_val, axis=0)\n",
    "        batch_var = jnp.var(return_val, axis=0)\n",
    "        batch_count = obs.shape[0]\n",
    "\n",
    "        delta = batch_mean - state.mean\n",
    "        tot_count = state.count + batch_count\n",
    "\n",
    "        new_mean = state.mean + delta * batch_count / tot_count\n",
    "        m_a = state.var * state.count\n",
    "        m_b = batch_var * batch_count\n",
    "        M2 = m_a + m_b + jnp.square(delta) * state.count * batch_count / tot_count\n",
    "        new_var = M2 / tot_count\n",
    "        new_count = tot_count\n",
    "\n",
    "        state = NormalizeVecRewEnvState(\n",
    "            mean=new_mean,\n",
    "            var=new_var,\n",
    "            count=new_count,\n",
    "            return_val=return_val,\n",
    "            env_state=env_state,\n",
    "        )\n",
    "        return obs, state, reward / jnp.sqrt(state.var + 1e-8), done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import numpy as np\n",
    "import optax\n",
    "from flax.linen.initializers import constant, orthogonal\n",
    "from typing import Sequence, NamedTuple, Any\n",
    "from flax.training.train_state import TrainState\n",
    "import distrax\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    action_dim: Sequence[int]\n",
    "    activation: str = \"tanh\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        if self.activation == \"relu\":\n",
    "            activation = nn.relu\n",
    "        else:\n",
    "            activation = nn.tanh\n",
    "        actor_mean = nn.Dense(\n",
    "            256, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\n",
    "        )(x)\n",
    "        actor_mean = activation(actor_mean)\n",
    "        actor_mean = nn.Dense(\n",
    "            256, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\n",
    "        )(actor_mean)\n",
    "        actor_mean = activation(actor_mean)\n",
    "        actor_mean = nn.Dense(\n",
    "            self.action_dim, kernel_init=orthogonal(0.01), bias_init=constant(0.0)\n",
    "        )(actor_mean)\n",
    "        actor_logtstd = self.param(\"log_std\", nn.initializers.zeros, (self.action_dim,))\n",
    "        pi = distrax.MultivariateNormalDiag(actor_mean, jnp.exp(actor_logtstd))\n",
    "\n",
    "        critic = nn.Dense(\n",
    "            256, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\n",
    "        )(x)\n",
    "        critic = activation(critic)\n",
    "        critic = nn.Dense(\n",
    "            256, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\n",
    "        )(critic)\n",
    "        critic = activation(critic)\n",
    "        critic = nn.Dense(1, kernel_init=orthogonal(1.0), bias_init=constant(0.0))(\n",
    "            critic\n",
    "        )\n",
    "\n",
    "        return pi, jnp.squeeze(critic, axis=-1)\n",
    "\n",
    "\n",
    "class Transition(NamedTuple):\n",
    "    done: jnp.ndarray\n",
    "    action: jnp.ndarray\n",
    "    value: jnp.ndarray\n",
    "    reward: jnp.ndarray\n",
    "    log_prob: jnp.ndarray\n",
    "    obs: jnp.ndarray\n",
    "    info: jnp.ndarray\n",
    "\n",
    "\n",
    "def make_train(config):\n",
    "    config[\"NUM_UPDATES\"] = (\n",
    "        config[\"TOTAL_TIMESTEPS\"] // config[\"NUM_STEPS\"] // config[\"NUM_ENVS\"]\n",
    "    )\n",
    "    config[\"MINIBATCH_SIZE\"] = (\n",
    "        config[\"NUM_ENVS\"] * config[\"NUM_STEPS\"] // config[\"NUM_MINIBATCHES\"]\n",
    "    )\n",
    "    print(config[\"MINIBATCH_SIZE\"])\n",
    "    env, env_params = BraxGymnaxWrapper(config[\"ENV_NAME\"]), None\n",
    "    env = LogWrapper(env)\n",
    "    env = ClipAction(env)\n",
    "    env = VecEnv(env)\n",
    "    if config[\"NORMALIZE_ENV\"]:\n",
    "        env = NormalizeVecObservation(env)\n",
    "        env = NormalizeVecReward(env, config[\"GAMMA\"])\n",
    "\n",
    "    def linear_schedule(count):\n",
    "        frac = (\n",
    "            1.0\n",
    "            - (count // (config[\"NUM_MINIBATCHES\"] * config[\"UPDATE_EPOCHS\"]))\n",
    "            / config[\"NUM_UPDATES\"]\n",
    "        )\n",
    "        return config[\"LR\"] * frac\n",
    "\n",
    "    def train(rng):\n",
    "        # INIT NETWORK\n",
    "        network = ActorCritic(\n",
    "            env.action_space(env_params).shape[0], activation=config[\"ACTIVATION\"]\n",
    "        )\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        init_x = jnp.zeros(env.observation_space(env_params).shape)\n",
    "        network_params = network.init(_rng, init_x)\n",
    "        if config[\"ANNEAL_LR\"]:\n",
    "            tx = optax.chain(\n",
    "                optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
    "                optax.adam(learning_rate=linear_schedule, eps=1e-5),\n",
    "            )\n",
    "        else:\n",
    "            tx = optax.chain(\n",
    "                optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
    "                optax.adam(config[\"LR\"], eps=1e-5),\n",
    "            )\n",
    "        train_state = TrainState.create(\n",
    "            apply_fn=network.apply,\n",
    "            params=network_params,\n",
    "            tx=tx,\n",
    "        )\n",
    "\n",
    "        # INIT ENV\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        reset_rng = jax.random.split(_rng, config[\"NUM_ENVS\"])\n",
    "        obsv, env_state = env.reset(reset_rng, env_params)\n",
    "\n",
    "        # TRAIN LOOP\n",
    "        def _update_step(runner_state, unused):\n",
    "            # COLLECT TRAJECTORIES\n",
    "            def _env_step(runner_state, unused):\n",
    "                train_state, env_state, last_obs, rng = runner_state\n",
    "\n",
    "                # SELECT ACTION\n",
    "                rng, _rng = jax.random.split(rng)\n",
    "                pi, value = network.apply(train_state.params, last_obs)\n",
    "                action = pi.sample(seed=_rng)\n",
    "                log_prob = pi.log_prob(action)\n",
    "\n",
    "                # STEP ENV\n",
    "                rng, _rng = jax.random.split(rng)\n",
    "                rng_step = jax.random.split(_rng, config[\"NUM_ENVS\"])\n",
    "                obsv, env_state, reward, done, info = env.step(\n",
    "                    rng_step, env_state, action, env_params\n",
    "                )\n",
    "                transition = Transition(\n",
    "                    done, action, value, reward, log_prob, last_obs, info\n",
    "                )\n",
    "                runner_state = (train_state, env_state, obsv, rng)\n",
    "                return runner_state, transition\n",
    "\n",
    "            runner_state, traj_batch = jax.lax.scan(\n",
    "                _env_step, runner_state, None, config[\"NUM_STEPS\"]\n",
    "            )\n",
    "\n",
    "            # CALCULATE ADVANTAGE\n",
    "            train_state, env_state, last_obs, rng = runner_state\n",
    "            _, last_val = network.apply(train_state.params, last_obs)\n",
    "\n",
    "            def _calculate_gae(traj_batch, last_val):\n",
    "                def _get_advantages(gae_and_next_value, transition):\n",
    "                    gae, next_value = gae_and_next_value\n",
    "                    done, value, reward = (\n",
    "                        transition.done,\n",
    "                        transition.value,\n",
    "                        transition.reward,\n",
    "                    )\n",
    "                    delta = reward + config[\"GAMMA\"] * next_value * (1 - done) - value\n",
    "                    gae = (\n",
    "                        delta\n",
    "                        + config[\"GAMMA\"] * config[\"GAE_LAMBDA\"] * (1 - done) * gae\n",
    "                    )\n",
    "                    return (gae, value), gae\n",
    "\n",
    "                _, advantages = jax.lax.scan(\n",
    "                    _get_advantages,\n",
    "                    (jnp.zeros_like(last_val), last_val),\n",
    "                    traj_batch,\n",
    "                    reverse=True,\n",
    "                    unroll=16,\n",
    "                )\n",
    "                return advantages, advantages + traj_batch.value\n",
    "\n",
    "            advantages, targets = _calculate_gae(traj_batch, last_val)\n",
    "\n",
    "            # UPDATE NETWORK\n",
    "            def _update_epoch(update_state, unused):\n",
    "                def _update_minbatch(train_state, batch_info):\n",
    "                    traj_batch, advantages, targets = batch_info\n",
    "\n",
    "                    def _loss_fn(params, traj_batch, gae, targets):\n",
    "                        # RERUN NETWORK\n",
    "                        pi, value = network.apply(params, traj_batch.obs)\n",
    "                        log_prob = pi.log_prob(traj_batch.action)\n",
    "\n",
    "                        # CALCULATE VALUE LOSS\n",
    "                        value_pred_clipped = traj_batch.value + (\n",
    "                            value - traj_batch.value\n",
    "                        ).clip(-config[\"CLIP_EPS\"], config[\"CLIP_EPS\"])\n",
    "                        value_losses = jnp.square(value - targets)\n",
    "                        value_losses_clipped = jnp.square(value_pred_clipped - targets)\n",
    "                        value_loss = (\n",
    "                            0.5 * jnp.maximum(value_losses, value_losses_clipped).mean()\n",
    "                        )\n",
    "\n",
    "                        # CALCULATE ACTOR LOSS\n",
    "                        ratio = jnp.exp(log_prob - traj_batch.log_prob)\n",
    "                        gae = (gae - gae.mean()) / (gae.std() + 1e-8)\n",
    "                        loss_actor1 = ratio * gae\n",
    "                        loss_actor2 = (\n",
    "                            jnp.clip(\n",
    "                                ratio,\n",
    "                                1.0 - config[\"CLIP_EPS\"],\n",
    "                                1.0 + config[\"CLIP_EPS\"],\n",
    "                            )\n",
    "                            * gae\n",
    "                        )\n",
    "                        loss_actor = -jnp.minimum(loss_actor1, loss_actor2)\n",
    "                        loss_actor = loss_actor.mean()\n",
    "                        entropy = pi.entropy().mean()\n",
    "\n",
    "                        total_loss = (\n",
    "                            loss_actor\n",
    "                            + config[\"VF_COEF\"] * value_loss\n",
    "                            - config[\"ENT_COEF\"] * entropy\n",
    "                        )\n",
    "                        return total_loss, (value_loss, loss_actor, entropy)\n",
    "\n",
    "                    grad_fn = jax.value_and_grad(_loss_fn, has_aux=True)\n",
    "                    total_loss, grads = grad_fn(\n",
    "                        train_state.params, traj_batch, advantages, targets\n",
    "                    )\n",
    "                    train_state = train_state.apply_gradients(grads=grads)\n",
    "                    return train_state, total_loss\n",
    "\n",
    "                train_state, traj_batch, advantages, targets, rng = update_state\n",
    "                rng, _rng = jax.random.split(rng)\n",
    "                batch_size = config[\"MINIBATCH_SIZE\"] * config[\"NUM_MINIBATCHES\"]\n",
    "                assert (\n",
    "                    batch_size == config[\"NUM_STEPS\"] * config[\"NUM_ENVS\"]\n",
    "                ), \"batch size must be equal to number of steps * number of envs\"\n",
    "                permutation = jax.random.permutation(_rng, batch_size)\n",
    "                batch = (traj_batch, advantages, targets)\n",
    "                batch = jax.tree_util.tree_map(\n",
    "                    lambda x: x.reshape((batch_size,) + x.shape[2:]), batch\n",
    "                )\n",
    "                shuffled_batch = jax.tree_util.tree_map(\n",
    "                    lambda x: jnp.take(x, permutation, axis=0), batch\n",
    "                )\n",
    "                minibatches = jax.tree_util.tree_map(\n",
    "                    lambda x: jnp.reshape(\n",
    "                        x, [config[\"NUM_MINIBATCHES\"], -1] + list(x.shape[1:])\n",
    "                    ),\n",
    "                    shuffled_batch,\n",
    "                )\n",
    "                train_state, total_loss = jax.lax.scan(\n",
    "                    _update_minbatch, train_state, minibatches\n",
    "                )\n",
    "                update_state = (train_state, traj_batch, advantages, targets, rng)\n",
    "                return update_state, total_loss\n",
    "\n",
    "            update_state = (train_state, traj_batch, advantages, targets, rng)\n",
    "            update_state, loss_info = jax.lax.scan(\n",
    "                _update_epoch, update_state, None, config[\"UPDATE_EPOCHS\"]\n",
    "            )\n",
    "            train_state = update_state[0]\n",
    "            metric = traj_batch.info\n",
    "            rng = update_state[-1]\n",
    "            if config.get(\"DEBUG\"):\n",
    "\n",
    "                def callback(info):\n",
    "                    return_values = info[\"returned_episode_returns\"][\n",
    "                        info[\"returned_episode\"]\n",
    "                    ]\n",
    "                    timesteps = (\n",
    "                        info[\"timestep\"][info[\"returned_episode\"]] * config[\"NUM_ENVS\"]\n",
    "                    )\n",
    "                    for t in range(len(timesteps)):\n",
    "                        print(\n",
    "                            f\"global step={timesteps[t]}, episodic return={return_values[t]}\"\n",
    "                        )\n",
    "\n",
    "                jax.debug.callback(callback, metric)\n",
    "\n",
    "            runner_state = (train_state, env_state, last_obs, rng)\n",
    "            return runner_state, metric\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        runner_state = (train_state, env_state, obsv, _rng)\n",
    "        print(config[\"NUM_UPDATES\"])\n",
    "        runner_state, metric = jax.lax.scan(\n",
    "            _update_step, runner_state, None, config[\"NUM_UPDATES\"]\n",
    "        )\n",
    "        return {\"runner_state\": runner_state, \"metrics\": metric}\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n",
      "48.0\n",
      "global step=20480, episodic return=10.685628890991211\n",
      "global step=20480, episodic return=10.193792343139648\n",
      "global step=22528, episodic return=13.86668872833252\n",
      "global step=22528, episodic return=13.20866584777832\n",
      "global step=24576, episodic return=12.736753463745117\n",
      "global step=24576, episodic return=14.77828598022461\n",
      "global step=24576, episodic return=12.179937362670898\n",
      "global step=24576, episodic return=12.075844764709473\n",
      "global step=24576, episodic return=16.386640548706055\n",
      "global step=24576, episodic return=13.504207611083984\n",
      "global step=24576, episodic return=14.985676765441895\n",
      "global step=26624, episodic return=14.530234336853027\n",
      "global step=26624, episodic return=16.713361740112305\n",
      "global step=26624, episodic return=13.284112930297852\n",
      "global step=28672, episodic return=9.308014869689941\n",
      "global step=28672, episodic return=16.11906623840332\n",
      "global step=28672, episodic return=15.568574905395508\n",
      "global step=28672, episodic return=14.099847793579102\n",
      "global step=28672, episodic return=18.166494369506836\n",
      "global step=28672, episodic return=15.47751235961914\n",
      "global step=28672, episodic return=10.570279121398926\n",
      "global step=28672, episodic return=16.030601501464844\n",
      "global step=28672, episodic return=15.547152519226074\n",
      "global step=28672, episodic return=15.329459190368652\n",
      "global step=28672, episodic return=16.762828826904297\n",
      "global step=30720, episodic return=18.816814422607422\n",
      "global step=30720, episodic return=15.401727676391602\n",
      "global step=30720, episodic return=16.281536102294922\n",
      "global step=30720, episodic return=16.005271911621094\n",
      "global step=30720, episodic return=15.779337882995605\n",
      "global step=30720, episodic return=19.40270233154297\n",
      "global step=30720, episodic return=17.656352996826172\n",
      "global step=30720, episodic return=16.010868072509766\n",
      "global step=30720, episodic return=18.493125915527344\n",
      "global step=30720, episodic return=16.30002784729004\n",
      "global step=30720, episodic return=20.44439125061035\n",
      "global step=30720, episodic return=14.993267059326172\n",
      "global step=30720, episodic return=18.888629913330078\n",
      "global step=30720, episodic return=21.12307357788086\n",
      "global step=30720, episodic return=16.948488235473633\n",
      "global step=30720, episodic return=13.461155891418457\n",
      "global step=30720, episodic return=19.560951232910156\n",
      "global step=30720, episodic return=12.293447494506836\n",
      "global step=32768, episodic return=16.442228317260742\n",
      "global step=32768, episodic return=15.956241607666016\n",
      "global step=32768, episodic return=21.148061752319336\n",
      "global step=32768, episodic return=21.143983840942383\n",
      "global step=32768, episodic return=15.550104141235352\n",
      "global step=32768, episodic return=15.576240539550781\n",
      "global step=32768, episodic return=16.120254516601562\n",
      "global step=32768, episodic return=19.904382705688477\n",
      "global step=32768, episodic return=22.65985107421875\n",
      "global step=32768, episodic return=17.187328338623047\n",
      "global step=32768, episodic return=21.156909942626953\n",
      "global step=32768, episodic return=21.467348098754883\n",
      "global step=32768, episodic return=22.09306526184082\n",
      "global step=32768, episodic return=12.641009330749512\n",
      "global step=32768, episodic return=15.750797271728516\n",
      "global step=32768, episodic return=18.654539108276367\n",
      "global step=32768, episodic return=19.335729598999023\n",
      "global step=32768, episodic return=16.536434173583984\n",
      "global step=32768, episodic return=16.717792510986328\n",
      "global step=32768, episodic return=16.821603775024414\n",
      "global step=32768, episodic return=18.547571182250977\n",
      "global step=32768, episodic return=14.475690841674805\n",
      "global step=32768, episodic return=17.469470977783203\n",
      "global step=32768, episodic return=19.11879539489746\n",
      "global step=32768, episodic return=18.388914108276367\n",
      "global step=32768, episodic return=20.202171325683594\n",
      "global step=34816, episodic return=25.856975555419922\n",
      "global step=34816, episodic return=19.021995544433594\n",
      "global step=34816, episodic return=21.61485481262207\n",
      "global step=34816, episodic return=13.909031867980957\n",
      "global step=34816, episodic return=12.416888236999512\n",
      "global step=34816, episodic return=13.238933563232422\n",
      "global step=34816, episodic return=19.321346282958984\n",
      "global step=34816, episodic return=22.329015731811523\n",
      "global step=34816, episodic return=24.251462936401367\n",
      "global step=34816, episodic return=23.283485412597656\n",
      "global step=34816, episodic return=26.276641845703125\n",
      "global step=34816, episodic return=20.06711196899414\n",
      "global step=34816, episodic return=20.421104431152344\n",
      "global step=34816, episodic return=19.553882598876953\n",
      "global step=34816, episodic return=18.106651306152344\n",
      "global step=34816, episodic return=21.98937225341797\n",
      "global step=34816, episodic return=23.652339935302734\n",
      "global step=34816, episodic return=18.40234375\n",
      "global step=36864, episodic return=23.988121032714844\n",
      "global step=36864, episodic return=26.093517303466797\n",
      "global step=36864, episodic return=14.013944625854492\n",
      "global step=36864, episodic return=22.287132263183594\n",
      "global step=36864, episodic return=20.87676239013672\n",
      "global step=36864, episodic return=20.674667358398438\n",
      "global step=36864, episodic return=24.651716232299805\n",
      "global step=36864, episodic return=18.545312881469727\n",
      "global step=36864, episodic return=21.356863021850586\n",
      "global step=36864, episodic return=23.884925842285156\n",
      "global step=36864, episodic return=23.985197067260742\n",
      "global step=36864, episodic return=20.029685974121094\n",
      "global step=36864, episodic return=21.908382415771484\n",
      "global step=36864, episodic return=25.680583953857422\n",
      "global step=36864, episodic return=25.94432258605957\n",
      "global step=36864, episodic return=22.015460968017578\n",
      "global step=36864, episodic return=26.254392623901367\n",
      "global step=36864, episodic return=24.81337547302246\n",
      "global step=36864, episodic return=28.744182586669922\n",
      "global step=36864, episodic return=17.910968780517578\n",
      "global step=36864, episodic return=21.223045349121094\n",
      "global step=36864, episodic return=21.954833984375\n",
      "global step=36864, episodic return=21.404037475585938\n",
      "global step=36864, episodic return=17.719308853149414\n",
      "global step=36864, episodic return=20.994911193847656\n",
      "global step=36864, episodic return=20.538251876831055\n",
      "global step=36864, episodic return=22.975805282592773\n",
      "global step=38912, episodic return=16.867345809936523\n",
      "global step=38912, episodic return=18.01235008239746\n",
      "global step=38912, episodic return=22.432741165161133\n",
      "global step=38912, episodic return=17.52576446533203\n",
      "global step=38912, episodic return=18.811969757080078\n",
      "global step=38912, episodic return=17.063926696777344\n",
      "global step=38912, episodic return=16.60073471069336\n",
      "global step=38912, episodic return=18.85556983947754\n",
      "global step=38912, episodic return=26.140466690063477\n",
      "global step=38912, episodic return=20.163040161132812\n",
      "global step=38912, episodic return=27.649675369262695\n",
      "global step=38912, episodic return=21.89653968811035\n",
      "global step=38912, episodic return=24.347579956054688\n",
      "global step=38912, episodic return=16.836423873901367\n",
      "global step=38912, episodic return=27.294599533081055\n",
      "global step=38912, episodic return=24.116111755371094\n",
      "global step=38912, episodic return=24.876367568969727\n",
      "global step=38912, episodic return=22.732450485229492\n",
      "global step=38912, episodic return=22.72971534729004\n",
      "global step=38912, episodic return=23.101531982421875\n",
      "global step=38912, episodic return=22.808259963989258\n",
      "global step=38912, episodic return=18.84086799621582\n",
      "global step=38912, episodic return=23.935087203979492\n",
      "global step=38912, episodic return=18.840822219848633\n",
      "global step=38912, episodic return=18.555383682250977\n",
      "global step=38912, episodic return=16.83243751525879\n",
      "global step=38912, episodic return=24.12140655517578\n",
      "global step=38912, episodic return=20.287540435791016\n",
      "global step=38912, episodic return=19.119983673095703\n",
      "global step=38912, episodic return=31.49516487121582\n",
      "global step=38912, episodic return=18.142314910888672\n",
      "global step=38912, episodic return=20.138452529907227\n",
      "global step=38912, episodic return=25.053159713745117\n",
      "global step=40960, episodic return=29.410606384277344\n",
      "global step=40960, episodic return=22.25177574157715\n",
      "global step=40960, episodic return=21.273435592651367\n",
      "global step=40960, episodic return=26.845664978027344\n",
      "global step=40960, episodic return=15.37002944946289\n",
      "global step=40960, episodic return=18.17685317993164\n",
      "global step=40960, episodic return=22.664682388305664\n",
      "global step=40960, episodic return=17.19867515563965\n",
      "global step=40960, episodic return=16.001876831054688\n",
      "global step=40960, episodic return=23.714303970336914\n",
      "global step=40960, episodic return=18.189430236816406\n",
      "global step=40960, episodic return=20.482952117919922\n",
      "global step=40960, episodic return=19.67450714111328\n",
      "global step=40960, episodic return=16.12676239013672\n",
      "global step=40960, episodic return=18.728221893310547\n",
      "global step=40960, episodic return=20.826751708984375\n",
      "global step=40960, episodic return=27.382980346679688\n",
      "global step=40960, episodic return=17.80940055847168\n",
      "global step=40960, episodic return=24.241708755493164\n",
      "global step=40960, episodic return=23.35724639892578\n",
      "global step=40960, episodic return=28.558879852294922\n",
      "global step=40960, episodic return=21.516887664794922\n",
      "global step=40960, episodic return=19.555177688598633\n",
      "global step=40960, episodic return=27.355274200439453\n",
      "global step=40960, episodic return=21.749422073364258\n",
      "global step=40960, episodic return=16.451486587524414\n",
      "global step=40960, episodic return=26.579792022705078\n",
      "global step=40960, episodic return=24.113277435302734\n",
      "global step=43008, episodic return=24.27043914794922\n",
      "global step=43008, episodic return=23.50433349609375\n",
      "global step=43008, episodic return=14.506328582763672\n",
      "global step=43008, episodic return=16.04592514038086\n",
      "global step=43008, episodic return=19.959171295166016\n",
      "global step=43008, episodic return=28.058088302612305\n",
      "global step=43008, episodic return=28.65365982055664\n",
      "global step=43008, episodic return=26.39136505126953\n",
      "global step=43008, episodic return=23.621259689331055\n",
      "global step=43008, episodic return=29.242778778076172\n",
      "global step=43008, episodic return=27.05797576904297\n",
      "global step=43008, episodic return=27.143463134765625\n",
      "global step=43008, episodic return=22.28116798400879\n",
      "global step=43008, episodic return=31.013349533081055\n",
      "global step=43008, episodic return=25.143184661865234\n",
      "global step=43008, episodic return=29.45466423034668\n",
      "global step=43008, episodic return=19.643993377685547\n",
      "global step=43008, episodic return=23.859683990478516\n",
      "global step=43008, episodic return=21.6304874420166\n",
      "global step=43008, episodic return=25.09838104248047\n",
      "global step=43008, episodic return=27.066165924072266\n",
      "global step=43008, episodic return=32.02644348144531\n",
      "global step=43008, episodic return=18.380708694458008\n",
      "global step=43008, episodic return=26.40215492248535\n",
      "global step=43008, episodic return=25.072736740112305\n",
      "global step=43008, episodic return=26.115821838378906\n",
      "global step=43008, episodic return=24.41419792175293\n",
      "global step=43008, episodic return=19.78545379638672\n",
      "global step=43008, episodic return=31.524927139282227\n",
      "global step=43008, episodic return=27.974538803100586\n",
      "global step=43008, episodic return=26.794198989868164\n",
      "global step=43008, episodic return=20.836687088012695\n",
      "global step=43008, episodic return=16.102027893066406\n",
      "global step=43008, episodic return=19.19239044189453\n",
      "global step=43008, episodic return=29.545875549316406\n",
      "global step=43008, episodic return=26.617528915405273\n",
      "global step=43008, episodic return=18.677141189575195\n",
      "global step=43008, episodic return=23.13477897644043\n",
      "global step=43008, episodic return=23.17583465576172\n",
      "global step=43008, episodic return=24.324176788330078\n",
      "global step=45056, episodic return=21.35059356689453\n",
      "global step=45056, episodic return=19.32880401611328\n",
      "global step=45056, episodic return=19.177553176879883\n",
      "global step=45056, episodic return=22.08258628845215\n",
      "global step=45056, episodic return=27.959924697875977\n",
      "global step=45056, episodic return=23.647754669189453\n",
      "global step=45056, episodic return=30.740921020507812\n",
      "global step=45056, episodic return=20.542831420898438\n",
      "global step=45056, episodic return=23.562450408935547\n",
      "global step=45056, episodic return=30.17879295349121\n",
      "global step=45056, episodic return=28.677091598510742\n",
      "global step=45056, episodic return=28.604759216308594\n",
      "global step=45056, episodic return=22.85089683532715\n",
      "global step=45056, episodic return=20.363893508911133\n",
      "global step=45056, episodic return=19.298215866088867\n",
      "global step=45056, episodic return=29.633333206176758\n",
      "global step=45056, episodic return=21.03466796875\n",
      "global step=45056, episodic return=24.7763671875\n",
      "global step=45056, episodic return=19.176128387451172\n",
      "global step=45056, episodic return=28.60778045654297\n",
      "global step=45056, episodic return=19.819408416748047\n",
      "global step=45056, episodic return=21.149484634399414\n",
      "global step=45056, episodic return=23.546794891357422\n",
      "global step=45056, episodic return=21.73059844970703\n",
      "global step=47104, episodic return=35.351715087890625\n",
      "global step=47104, episodic return=29.570341110229492\n",
      "global step=47104, episodic return=25.624509811401367\n",
      "global step=47104, episodic return=18.56440544128418\n",
      "global step=47104, episodic return=23.455427169799805\n",
      "global step=47104, episodic return=19.485116958618164\n",
      "global step=47104, episodic return=24.030006408691406\n",
      "global step=47104, episodic return=38.21248245239258\n",
      "global step=47104, episodic return=20.590267181396484\n",
      "global step=47104, episodic return=24.193775177001953\n",
      "global step=47104, episodic return=32.20225524902344\n",
      "global step=47104, episodic return=17.637908935546875\n",
      "global step=47104, episodic return=26.52821159362793\n",
      "global step=47104, episodic return=13.722243309020996\n",
      "global step=47104, episodic return=38.27633285522461\n",
      "global step=47104, episodic return=30.73414421081543\n",
      "global step=47104, episodic return=26.685317993164062\n",
      "global step=47104, episodic return=29.455890655517578\n",
      "global step=47104, episodic return=28.089645385742188\n",
      "global step=47104, episodic return=22.289073944091797\n",
      "global step=47104, episodic return=19.589351654052734\n",
      "global step=47104, episodic return=36.980995178222656\n",
      "global step=47104, episodic return=22.47372817993164\n",
      "global step=49152, episodic return=32.199317932128906\n",
      "global step=49152, episodic return=32.879127502441406\n",
      "global step=49152, episodic return=24.735849380493164\n",
      "global step=49152, episodic return=21.577106475830078\n",
      "global step=49152, episodic return=21.379737854003906\n",
      "global step=49152, episodic return=21.402389526367188\n",
      "global step=49152, episodic return=28.45692253112793\n",
      "global step=49152, episodic return=34.85997009277344\n",
      "global step=49152, episodic return=32.75640869140625\n",
      "global step=49152, episodic return=25.215024948120117\n",
      "global step=49152, episodic return=38.94490432739258\n",
      "global step=49152, episodic return=26.08774185180664\n",
      "global step=49152, episodic return=23.870025634765625\n",
      "global step=49152, episodic return=30.01303482055664\n",
      "global step=49152, episodic return=20.790647506713867\n",
      "global step=49152, episodic return=28.08463478088379\n",
      "global step=49152, episodic return=25.382108688354492\n",
      "global step=49152, episodic return=17.536331176757812\n",
      "global step=49152, episodic return=18.193166732788086\n",
      "global step=49152, episodic return=37.44208526611328\n",
      "global step=49152, episodic return=37.307987213134766\n",
      "global step=49152, episodic return=28.035385131835938\n",
      "global step=49152, episodic return=31.140897750854492\n",
      "global step=49152, episodic return=24.539783477783203\n",
      "global step=49152, episodic return=25.870311737060547\n",
      "global step=49152, episodic return=26.445098876953125\n",
      "global step=49152, episodic return=37.23722839355469\n",
      "global step=49152, episodic return=28.70014762878418\n",
      "global step=49152, episodic return=30.81192970275879\n",
      "global step=49152, episodic return=19.688575744628906\n",
      "global step=49152, episodic return=32.95855712890625\n",
      "global step=51200, episodic return=34.18647766113281\n",
      "global step=51200, episodic return=34.27644348144531\n",
      "global step=51200, episodic return=22.159198760986328\n",
      "global step=51200, episodic return=20.323528289794922\n",
      "global step=51200, episodic return=29.639854431152344\n",
      "global step=51200, episodic return=26.905029296875\n",
      "global step=51200, episodic return=25.20400047302246\n",
      "global step=51200, episodic return=28.72113800048828\n",
      "global step=51200, episodic return=25.913543701171875\n",
      "global step=51200, episodic return=22.356714248657227\n",
      "global step=51200, episodic return=23.509422302246094\n",
      "global step=51200, episodic return=22.727903366088867\n",
      "global step=51200, episodic return=40.37093734741211\n",
      "global step=51200, episodic return=23.1914005279541\n",
      "global step=51200, episodic return=19.396398544311523\n",
      "global step=51200, episodic return=34.642765045166016\n",
      "global step=51200, episodic return=28.138463973999023\n",
      "global step=51200, episodic return=17.682504653930664\n",
      "global step=51200, episodic return=17.755578994750977\n",
      "global step=51200, episodic return=35.449527740478516\n",
      "global step=51200, episodic return=34.87716293334961\n",
      "global step=51200, episodic return=31.45764923095703\n",
      "global step=51200, episodic return=25.50323486328125\n",
      "global step=51200, episodic return=14.983596801757812\n",
      "global step=51200, episodic return=28.813003540039062\n",
      "global step=51200, episodic return=20.24720573425293\n",
      "global step=51200, episodic return=31.106618881225586\n",
      "global step=51200, episodic return=22.038646697998047\n",
      "global step=51200, episodic return=19.376380920410156\n",
      "global step=51200, episodic return=31.47722625732422\n",
      "global step=51200, episodic return=26.013952255249023\n",
      "global step=51200, episodic return=36.45209884643555\n",
      "global step=51200, episodic return=43.14870834350586\n",
      "global step=53248, episodic return=22.862215042114258\n",
      "global step=53248, episodic return=30.554895401000977\n",
      "global step=53248, episodic return=29.013309478759766\n",
      "global step=53248, episodic return=35.858619689941406\n",
      "global step=53248, episodic return=21.8519229888916\n",
      "global step=53248, episodic return=26.415969848632812\n",
      "global step=53248, episodic return=37.848609924316406\n",
      "global step=53248, episodic return=35.02204895019531\n",
      "global step=53248, episodic return=28.59773063659668\n",
      "global step=53248, episodic return=36.120948791503906\n",
      "global step=53248, episodic return=27.387495040893555\n",
      "global step=53248, episodic return=25.28722381591797\n",
      "global step=53248, episodic return=26.93390655517578\n",
      "global step=53248, episodic return=28.00735855102539\n",
      "global step=53248, episodic return=38.10538864135742\n",
      "global step=53248, episodic return=32.94920349121094\n",
      "global step=53248, episodic return=30.57097816467285\n",
      "global step=53248, episodic return=39.937320709228516\n",
      "global step=53248, episodic return=31.653379440307617\n",
      "global step=53248, episodic return=13.95693302154541\n",
      "global step=53248, episodic return=22.15110969543457\n",
      "global step=53248, episodic return=30.629541397094727\n",
      "global step=53248, episodic return=26.72928810119629\n",
      "global step=53248, episodic return=34.15020751953125\n",
      "global step=53248, episodic return=40.69041442871094\n",
      "global step=53248, episodic return=29.737287521362305\n",
      "global step=53248, episodic return=28.61095428466797\n",
      "global step=53248, episodic return=28.35843849182129\n",
      "global step=53248, episodic return=34.81770706176758\n",
      "global step=53248, episodic return=22.515626907348633\n",
      "global step=53248, episodic return=27.73712921142578\n",
      "global step=53248, episodic return=37.28695297241211\n",
      "global step=53248, episodic return=27.346790313720703\n",
      "global step=53248, episodic return=27.675247192382812\n",
      "global step=53248, episodic return=32.43890380859375\n",
      "global step=55296, episodic return=23.80413246154785\n",
      "global step=55296, episodic return=33.13642883300781\n",
      "global step=55296, episodic return=31.435935974121094\n",
      "global step=55296, episodic return=27.019975662231445\n",
      "global step=55296, episodic return=39.106666564941406\n",
      "global step=55296, episodic return=27.924148559570312\n",
      "global step=55296, episodic return=24.512548446655273\n",
      "global step=55296, episodic return=35.019264221191406\n",
      "global step=55296, episodic return=31.13568115234375\n",
      "global step=55296, episodic return=28.673236846923828\n",
      "global step=55296, episodic return=49.51080322265625\n",
      "global step=55296, episodic return=26.623661041259766\n",
      "global step=55296, episodic return=22.221948623657227\n",
      "global step=55296, episodic return=29.56812858581543\n",
      "global step=55296, episodic return=33.712528228759766\n",
      "global step=55296, episodic return=22.359262466430664\n",
      "global step=55296, episodic return=23.024593353271484\n",
      "global step=55296, episodic return=27.840843200683594\n",
      "global step=55296, episodic return=25.47406005859375\n",
      "global step=55296, episodic return=30.83399200439453\n",
      "global step=55296, episodic return=23.56839370727539\n",
      "global step=55296, episodic return=40.72822570800781\n",
      "global step=55296, episodic return=32.56652069091797\n",
      "global step=55296, episodic return=34.71590805053711\n",
      "global step=55296, episodic return=35.70831298828125\n",
      "global step=57344, episodic return=45.20237350463867\n",
      "global step=57344, episodic return=26.654787063598633\n",
      "global step=57344, episodic return=40.23851013183594\n",
      "global step=57344, episodic return=26.933622360229492\n",
      "global step=57344, episodic return=25.683990478515625\n",
      "global step=57344, episodic return=24.164936065673828\n",
      "global step=57344, episodic return=29.04559898376465\n",
      "global step=57344, episodic return=52.321102142333984\n",
      "global step=57344, episodic return=25.108047485351562\n",
      "global step=57344, episodic return=26.385311126708984\n",
      "global step=57344, episodic return=23.481481552124023\n",
      "global step=57344, episodic return=30.540834426879883\n",
      "global step=57344, episodic return=23.977344512939453\n",
      "global step=57344, episodic return=41.33951950073242\n",
      "global step=57344, episodic return=34.162559509277344\n",
      "global step=57344, episodic return=31.50673484802246\n",
      "global step=57344, episodic return=35.70416259765625\n",
      "global step=57344, episodic return=40.91887664794922\n",
      "global step=57344, episodic return=43.59657287597656\n",
      "global step=57344, episodic return=33.61865234375\n",
      "global step=57344, episodic return=28.12646484375\n",
      "global step=57344, episodic return=33.79237365722656\n",
      "global step=57344, episodic return=26.447925567626953\n",
      "global step=57344, episodic return=42.845882415771484\n",
      "global step=57344, episodic return=35.20404815673828\n",
      "global step=57344, episodic return=22.798120498657227\n",
      "global step=57344, episodic return=28.77340316772461\n",
      "global step=57344, episodic return=23.057876586914062\n",
      "global step=59392, episodic return=29.297565460205078\n",
      "global step=59392, episodic return=24.804780960083008\n",
      "global step=59392, episodic return=19.14597511291504\n",
      "global step=59392, episodic return=38.217742919921875\n",
      "global step=59392, episodic return=34.86687469482422\n",
      "global step=59392, episodic return=36.041160583496094\n",
      "global step=59392, episodic return=22.011255264282227\n",
      "global step=59392, episodic return=41.79230880737305\n",
      "global step=59392, episodic return=27.024389266967773\n",
      "global step=59392, episodic return=36.7389030456543\n",
      "global step=59392, episodic return=30.483898162841797\n",
      "global step=59392, episodic return=28.668922424316406\n",
      "global step=59392, episodic return=39.69443893432617\n",
      "global step=59392, episodic return=37.552791595458984\n",
      "global step=59392, episodic return=29.503582000732422\n",
      "global step=59392, episodic return=21.909767150878906\n",
      "global step=59392, episodic return=17.498435974121094\n",
      "global step=59392, episodic return=29.99846076965332\n",
      "global step=59392, episodic return=34.546329498291016\n",
      "global step=59392, episodic return=34.27265167236328\n",
      "global step=59392, episodic return=35.417423248291016\n",
      "global step=59392, episodic return=19.988035202026367\n",
      "global step=59392, episodic return=21.836769104003906\n",
      "global step=59392, episodic return=40.32497787475586\n",
      "global step=59392, episodic return=45.425743103027344\n",
      "global step=59392, episodic return=35.19851303100586\n",
      "global step=59392, episodic return=35.697227478027344\n",
      "global step=59392, episodic return=27.589149475097656\n",
      "global step=61440, episodic return=32.38143539428711\n",
      "global step=61440, episodic return=17.628677368164062\n",
      "global step=61440, episodic return=36.13772201538086\n",
      "global step=61440, episodic return=23.55660057067871\n",
      "global step=61440, episodic return=35.97038650512695\n",
      "global step=61440, episodic return=27.02533721923828\n",
      "global step=61440, episodic return=41.5787239074707\n",
      "global step=61440, episodic return=10.538237571716309\n",
      "global step=61440, episodic return=30.704885482788086\n",
      "global step=61440, episodic return=50.10508728027344\n",
      "global step=61440, episodic return=32.668643951416016\n",
      "global step=61440, episodic return=33.39863204956055\n",
      "global step=61440, episodic return=36.62331008911133\n",
      "global step=61440, episodic return=30.940383911132812\n",
      "global step=61440, episodic return=42.70124053955078\n",
      "global step=61440, episodic return=29.19966697692871\n",
      "global step=61440, episodic return=30.092044830322266\n",
      "global step=61440, episodic return=25.192882537841797\n",
      "global step=61440, episodic return=43.92832946777344\n",
      "global step=61440, episodic return=30.675432205200195\n",
      "global step=61440, episodic return=20.769977569580078\n",
      "global step=61440, episodic return=34.8272590637207\n",
      "global step=61440, episodic return=24.380203247070312\n",
      "global step=63488, episodic return=48.933719635009766\n",
      "global step=63488, episodic return=23.691255569458008\n",
      "global step=63488, episodic return=26.583032608032227\n",
      "global step=63488, episodic return=30.205997467041016\n",
      "global step=63488, episodic return=27.095129013061523\n",
      "global step=63488, episodic return=49.398048400878906\n",
      "global step=63488, episodic return=40.1208610534668\n",
      "global step=63488, episodic return=42.01823806762695\n",
      "global step=63488, episodic return=28.447580337524414\n",
      "global step=63488, episodic return=41.272247314453125\n",
      "global step=63488, episodic return=40.00333023071289\n",
      "global step=63488, episodic return=37.099891662597656\n",
      "global step=63488, episodic return=28.649818420410156\n",
      "global step=63488, episodic return=48.306156158447266\n",
      "global step=63488, episodic return=21.129980087280273\n",
      "global step=63488, episodic return=37.85235595703125\n",
      "global step=63488, episodic return=31.71123504638672\n",
      "global step=63488, episodic return=37.29617691040039\n",
      "global step=63488, episodic return=35.002830505371094\n",
      "global step=63488, episodic return=32.4979362487793\n",
      "global step=63488, episodic return=30.270416259765625\n",
      "global step=63488, episodic return=21.673877716064453\n",
      "global step=63488, episodic return=45.02346420288086\n",
      "global step=63488, episodic return=32.42424011230469\n",
      "global step=63488, episodic return=32.81513595581055\n",
      "global step=63488, episodic return=26.113361358642578\n",
      "global step=63488, episodic return=26.30066680908203\n",
      "global step=63488, episodic return=31.574644088745117\n",
      "global step=63488, episodic return=31.35463523864746\n",
      "global step=63488, episodic return=34.169132232666016\n",
      "global step=63488, episodic return=29.360992431640625\n",
      "global step=63488, episodic return=45.6995735168457\n",
      "global step=63488, episodic return=32.57508087158203\n",
      "global step=63488, episodic return=41.0063591003418\n",
      "global step=63488, episodic return=40.32864761352539\n",
      "global step=63488, episodic return=30.86667823791504\n",
      "global step=63488, episodic return=24.290393829345703\n",
      "global step=63488, episodic return=43.18760681152344\n",
      "global step=63488, episodic return=28.791522979736328\n",
      "global step=65536, episodic return=34.12202835083008\n",
      "global step=65536, episodic return=49.221290588378906\n",
      "global step=65536, episodic return=34.45927047729492\n",
      "global step=65536, episodic return=26.604169845581055\n",
      "global step=65536, episodic return=32.51774978637695\n",
      "global step=65536, episodic return=40.11806106567383\n",
      "global step=65536, episodic return=41.2730598449707\n",
      "global step=65536, episodic return=29.77161979675293\n",
      "global step=65536, episodic return=34.34667205810547\n",
      "global step=65536, episodic return=26.326457977294922\n",
      "global step=65536, episodic return=34.15645980834961\n",
      "global step=65536, episodic return=40.91560745239258\n",
      "global step=65536, episodic return=36.016597747802734\n",
      "global step=65536, episodic return=27.164995193481445\n",
      "global step=65536, episodic return=42.04313659667969\n",
      "global step=65536, episodic return=18.30794334411621\n",
      "global step=65536, episodic return=39.53874588012695\n",
      "global step=65536, episodic return=46.78120803833008\n",
      "global step=65536, episodic return=34.39254379272461\n",
      "global step=65536, episodic return=29.071794509887695\n",
      "global step=65536, episodic return=25.958044052124023\n",
      "global step=65536, episodic return=19.740772247314453\n",
      "global step=65536, episodic return=42.361637115478516\n",
      "global step=65536, episodic return=47.7075309753418\n",
      "global step=65536, episodic return=40.780799865722656\n",
      "global step=65536, episodic return=32.55905532836914\n",
      "global step=65536, episodic return=32.755821228027344\n",
      "global step=65536, episodic return=43.043548583984375\n",
      "global step=65536, episodic return=40.599971771240234\n",
      "global step=65536, episodic return=47.67680740356445\n",
      "global step=67584, episodic return=35.6683464050293\n",
      "global step=67584, episodic return=39.15673065185547\n",
      "global step=67584, episodic return=14.112594604492188\n",
      "global step=67584, episodic return=26.72957992553711\n",
      "global step=67584, episodic return=34.121185302734375\n",
      "global step=67584, episodic return=34.02504348754883\n",
      "global step=67584, episodic return=40.86854934692383\n",
      "global step=67584, episodic return=24.760297775268555\n",
      "global step=67584, episodic return=38.31123733520508\n",
      "global step=67584, episodic return=43.27455520629883\n",
      "global step=67584, episodic return=32.310821533203125\n",
      "global step=67584, episodic return=28.35151481628418\n",
      "global step=67584, episodic return=41.3497314453125\n",
      "global step=67584, episodic return=45.58325958251953\n",
      "global step=67584, episodic return=43.876888275146484\n",
      "global step=67584, episodic return=41.83071517944336\n",
      "global step=67584, episodic return=25.566333770751953\n",
      "global step=67584, episodic return=54.364192962646484\n",
      "global step=67584, episodic return=48.61988067626953\n",
      "global step=67584, episodic return=28.989782333374023\n",
      "global step=67584, episodic return=24.419979095458984\n",
      "global step=67584, episodic return=22.581300735473633\n",
      "global step=69632, episodic return=44.08892059326172\n",
      "global step=69632, episodic return=33.29979705810547\n",
      "global step=69632, episodic return=23.917545318603516\n",
      "global step=69632, episodic return=37.4083366394043\n",
      "global step=69632, episodic return=30.953872680664062\n",
      "global step=69632, episodic return=30.516210556030273\n",
      "global step=69632, episodic return=33.48592758178711\n",
      "global step=69632, episodic return=34.49991226196289\n",
      "global step=69632, episodic return=34.78209686279297\n",
      "global step=69632, episodic return=45.22545623779297\n",
      "global step=69632, episodic return=35.988487243652344\n",
      "global step=69632, episodic return=31.70811653137207\n",
      "global step=69632, episodic return=45.64182662963867\n",
      "global step=69632, episodic return=53.84579086303711\n",
      "global step=69632, episodic return=53.56898880004883\n",
      "global step=69632, episodic return=33.91122817993164\n",
      "global step=69632, episodic return=25.97987174987793\n",
      "global step=69632, episodic return=39.891658782958984\n",
      "global step=69632, episodic return=48.67995834350586\n",
      "global step=69632, episodic return=41.00721740722656\n",
      "global step=69632, episodic return=38.40771484375\n",
      "global step=69632, episodic return=45.48539733886719\n",
      "global step=69632, episodic return=46.99884796142578\n",
      "global step=69632, episodic return=30.8621883392334\n",
      "global step=71680, episodic return=41.218971252441406\n",
      "global step=71680, episodic return=31.529430389404297\n",
      "global step=71680, episodic return=40.22294616699219\n",
      "global step=71680, episodic return=26.848047256469727\n",
      "global step=71680, episodic return=51.61845397949219\n",
      "global step=71680, episodic return=28.392696380615234\n",
      "global step=71680, episodic return=40.00197219848633\n",
      "global step=71680, episodic return=50.89640426635742\n",
      "global step=71680, episodic return=42.02642822265625\n",
      "global step=71680, episodic return=40.036563873291016\n",
      "global step=71680, episodic return=39.43373107910156\n",
      "global step=71680, episodic return=25.426542282104492\n",
      "global step=71680, episodic return=41.1839485168457\n",
      "global step=71680, episodic return=43.85917282104492\n",
      "global step=71680, episodic return=48.67076873779297\n",
      "global step=71680, episodic return=31.50090217590332\n",
      "global step=71680, episodic return=27.883779525756836\n",
      "global step=71680, episodic return=30.168598175048828\n",
      "global step=71680, episodic return=50.3394775390625\n",
      "global step=71680, episodic return=22.931198120117188\n",
      "global step=71680, episodic return=35.745426177978516\n",
      "global step=71680, episodic return=39.315879821777344\n",
      "global step=71680, episodic return=34.38380432128906\n",
      "global step=71680, episodic return=30.928241729736328\n",
      "global step=71680, episodic return=49.171852111816406\n",
      "global step=71680, episodic return=39.63232421875\n",
      "global step=71680, episodic return=42.45892333984375\n",
      "global step=73728, episodic return=35.395347595214844\n",
      "global step=73728, episodic return=47.52314758300781\n",
      "global step=73728, episodic return=21.76952362060547\n",
      "global step=73728, episodic return=40.94875717163086\n",
      "global step=73728, episodic return=24.071033477783203\n",
      "global step=73728, episodic return=36.98681640625\n",
      "global step=73728, episodic return=42.2757453918457\n",
      "global step=73728, episodic return=36.021026611328125\n",
      "global step=73728, episodic return=29.518857955932617\n",
      "global step=73728, episodic return=44.02521896362305\n",
      "global step=73728, episodic return=30.843490600585938\n",
      "global step=73728, episodic return=30.63840675354004\n",
      "global step=73728, episodic return=32.366947174072266\n",
      "global step=73728, episodic return=28.04352378845215\n",
      "global step=73728, episodic return=45.80836868286133\n",
      "global step=73728, episodic return=40.60174560546875\n",
      "global step=73728, episodic return=37.84845733642578\n",
      "global step=73728, episodic return=33.95695495605469\n",
      "global step=73728, episodic return=28.090059280395508\n",
      "global step=73728, episodic return=30.241069793701172\n",
      "global step=73728, episodic return=44.358741760253906\n",
      "global step=73728, episodic return=38.14253616333008\n",
      "global step=73728, episodic return=27.433713912963867\n",
      "global step=73728, episodic return=52.21904373168945\n",
      "global step=73728, episodic return=36.00841522216797\n",
      "global step=73728, episodic return=25.564512252807617\n",
      "global step=75776, episodic return=42.901493072509766\n",
      "global step=75776, episodic return=16.48125648498535\n",
      "global step=75776, episodic return=14.728368759155273\n",
      "global step=75776, episodic return=45.66495132446289\n",
      "global step=75776, episodic return=33.436363220214844\n",
      "global step=75776, episodic return=31.309173583984375\n",
      "global step=75776, episodic return=26.967575073242188\n",
      "global step=75776, episodic return=38.31289291381836\n",
      "global step=75776, episodic return=38.867496490478516\n",
      "global step=75776, episodic return=24.673908233642578\n",
      "global step=75776, episodic return=30.617341995239258\n",
      "global step=75776, episodic return=52.671287536621094\n",
      "global step=75776, episodic return=38.185813903808594\n",
      "global step=75776, episodic return=41.234458923339844\n",
      "global step=75776, episodic return=33.77382278442383\n",
      "global step=75776, episodic return=43.87181091308594\n",
      "global step=75776, episodic return=44.989479064941406\n",
      "global step=75776, episodic return=54.75817108154297\n",
      "global step=75776, episodic return=59.538089752197266\n",
      "global step=75776, episodic return=25.11825180053711\n",
      "global step=75776, episodic return=34.45638656616211\n",
      "global step=75776, episodic return=27.534809112548828\n",
      "global step=75776, episodic return=27.826629638671875\n",
      "global step=75776, episodic return=31.44725799560547\n",
      "global step=75776, episodic return=56.35540008544922\n",
      "global step=77824, episodic return=38.03589630126953\n",
      "global step=77824, episodic return=34.44473648071289\n",
      "global step=77824, episodic return=39.260555267333984\n",
      "global step=77824, episodic return=39.376407623291016\n",
      "global step=77824, episodic return=46.61003112792969\n",
      "global step=77824, episodic return=36.41695785522461\n",
      "global step=77824, episodic return=33.67654037475586\n",
      "global step=77824, episodic return=48.33616256713867\n",
      "global step=77824, episodic return=33.087318420410156\n",
      "global step=77824, episodic return=28.479652404785156\n",
      "global step=77824, episodic return=44.268280029296875\n",
      "global step=77824, episodic return=41.11094665527344\n",
      "global step=77824, episodic return=47.24707794189453\n",
      "global step=77824, episodic return=40.733551025390625\n",
      "global step=77824, episodic return=52.87492370605469\n",
      "global step=77824, episodic return=41.77227020263672\n",
      "global step=77824, episodic return=56.51107406616211\n",
      "global step=77824, episodic return=20.49813461303711\n",
      "global step=77824, episodic return=36.00505828857422\n",
      "global step=79872, episodic return=55.45173263549805\n",
      "global step=79872, episodic return=43.49270248413086\n",
      "global step=79872, episodic return=26.86600685119629\n",
      "global step=79872, episodic return=30.94988250732422\n",
      "global step=79872, episodic return=30.253583908081055\n",
      "global step=79872, episodic return=26.11013412475586\n",
      "global step=79872, episodic return=57.28489685058594\n",
      "global step=79872, episodic return=42.22966766357422\n",
      "global step=79872, episodic return=54.02864456176758\n",
      "global step=79872, episodic return=39.827754974365234\n",
      "global step=79872, episodic return=31.508678436279297\n",
      "global step=79872, episodic return=52.87373733520508\n",
      "global step=79872, episodic return=47.05927276611328\n",
      "global step=79872, episodic return=41.04296112060547\n",
      "global step=79872, episodic return=57.25101089477539\n",
      "global step=79872, episodic return=39.224365234375\n",
      "global step=79872, episodic return=19.937362670898438\n",
      "global step=79872, episodic return=35.59126281738281\n",
      "global step=79872, episodic return=47.45083236694336\n",
      "global step=79872, episodic return=41.72898864746094\n",
      "global step=79872, episodic return=26.717815399169922\n",
      "global step=81920, episodic return=36.855106353759766\n",
      "global step=81920, episodic return=33.3768310546875\n",
      "global step=81920, episodic return=33.348350524902344\n",
      "global step=81920, episodic return=48.02663803100586\n",
      "global step=81920, episodic return=51.03992462158203\n",
      "global step=81920, episodic return=45.901031494140625\n",
      "global step=81920, episodic return=37.16529083251953\n",
      "global step=81920, episodic return=38.437923431396484\n",
      "global step=81920, episodic return=29.465375900268555\n",
      "global step=81920, episodic return=44.79658889770508\n",
      "global step=81920, episodic return=37.64340591430664\n",
      "global step=81920, episodic return=43.90471649169922\n",
      "global step=81920, episodic return=50.90624237060547\n",
      "global step=81920, episodic return=37.11428451538086\n",
      "global step=81920, episodic return=42.336421966552734\n",
      "global step=81920, episodic return=38.61501693725586\n",
      "global step=81920, episodic return=34.304100036621094\n",
      "global step=81920, episodic return=32.52204513549805\n",
      "global step=83968, episodic return=47.11292266845703\n",
      "global step=83968, episodic return=63.490474700927734\n",
      "global step=83968, episodic return=34.96117401123047\n",
      "global step=83968, episodic return=62.581459045410156\n",
      "global step=83968, episodic return=26.849899291992188\n",
      "global step=83968, episodic return=49.89193344116211\n",
      "global step=83968, episodic return=25.158916473388672\n",
      "global step=83968, episodic return=45.77892303466797\n",
      "global step=83968, episodic return=67.24373626708984\n",
      "global step=83968, episodic return=32.029884338378906\n",
      "global step=83968, episodic return=31.531726837158203\n",
      "global step=83968, episodic return=39.869873046875\n",
      "global step=86016, episodic return=41.791725158691406\n",
      "global step=86016, episodic return=41.65233612060547\n",
      "global step=86016, episodic return=48.541236877441406\n",
      "global step=86016, episodic return=34.690956115722656\n",
      "global step=86016, episodic return=45.458526611328125\n",
      "global step=86016, episodic return=46.4259033203125\n",
      "global step=86016, episodic return=63.5446891784668\n",
      "global step=86016, episodic return=36.002227783203125\n",
      "global step=86016, episodic return=40.69770812988281\n",
      "global step=86016, episodic return=47.59003448486328\n",
      "global step=86016, episodic return=26.584491729736328\n",
      "global step=86016, episodic return=38.5903205871582\n",
      "global step=86016, episodic return=50.064857482910156\n",
      "global step=86016, episodic return=33.93574142456055\n",
      "global step=86016, episodic return=37.95604705810547\n",
      "global step=86016, episodic return=33.288726806640625\n",
      "global step=86016, episodic return=54.86971664428711\n",
      "global step=86016, episodic return=35.788978576660156\n",
      "global step=86016, episodic return=32.83597183227539\n",
      "global step=86016, episodic return=60.04362487792969\n",
      "global step=86016, episodic return=28.12453842163086\n",
      "global step=86016, episodic return=19.98602294921875\n",
      "global step=86016, episodic return=36.58026885986328\n",
      "global step=88064, episodic return=41.91767883300781\n",
      "global step=88064, episodic return=31.137630462646484\n",
      "global step=88064, episodic return=35.758907318115234\n",
      "global step=88064, episodic return=42.520782470703125\n",
      "global step=88064, episodic return=19.5266056060791\n",
      "global step=88064, episodic return=53.86943817138672\n",
      "global step=88064, episodic return=30.169818878173828\n",
      "global step=88064, episodic return=38.02911376953125\n",
      "global step=88064, episodic return=50.27707290649414\n",
      "global step=88064, episodic return=64.94371795654297\n",
      "global step=90112, episodic return=35.36225128173828\n",
      "global step=90112, episodic return=35.09468460083008\n",
      "global step=90112, episodic return=34.420772552490234\n",
      "global step=90112, episodic return=37.77473449707031\n",
      "global step=90112, episodic return=47.49142074584961\n",
      "global step=92160, episodic return=57.51888656616211\n",
      "global step=92160, episodic return=56.073238372802734\n",
      "global step=92160, episodic return=54.668983459472656\n",
      "global step=92160, episodic return=47.117164611816406\n",
      "global step=92160, episodic return=45.377899169921875\n",
      "global step=92160, episodic return=44.51808166503906\n",
      "global step=92160, episodic return=53.201148986816406\n",
      "global step=92160, episodic return=26.451303482055664\n",
      "global step=92160, episodic return=55.187530517578125\n",
      "global step=94208, episodic return=48.39097595214844\n",
      "global step=94208, episodic return=49.480186462402344\n",
      "global step=94208, episodic return=49.251617431640625\n",
      "global step=94208, episodic return=17.071578979492188\n",
      "global step=94208, episodic return=39.640872955322266\n",
      "global step=94208, episodic return=59.1789665222168\n",
      "global step=94208, episodic return=32.44090270996094\n",
      "global step=94208, episodic return=27.417848587036133\n",
      "global step=94208, episodic return=39.41566848754883\n",
      "global step=96256, episodic return=33.147647857666016\n",
      "global step=96256, episodic return=45.36453628540039\n",
      "global step=96256, episodic return=54.41092300415039\n",
      "global step=96256, episodic return=31.024791717529297\n",
      "global step=96256, episodic return=22.94424057006836\n",
      "global step=96256, episodic return=74.30975341796875\n",
      "global step=96256, episodic return=57.1678466796875\n",
      "global step=96256, episodic return=46.55979919433594\n",
      "global step=96256, episodic return=54.91305160522461\n",
      "global step=96256, episodic return=36.424583435058594\n",
      "global step=96256, episodic return=41.565433502197266\n",
      "global step=96256, episodic return=54.002140045166016\n",
      "global step=98304, episodic return=78.9653549194336\n",
      "global step=98304, episodic return=21.593387603759766\n",
      "global step=98304, episodic return=34.34846878051758\n",
      "global step=98304, episodic return=37.731380462646484\n",
      "global step=98304, episodic return=45.65012741088867\n",
      "global step=98304, episodic return=18.79020118713379\n",
      "global step=98304, episodic return=43.542945861816406\n",
      "global step=98304, episodic return=66.42305755615234\n",
      "global step=98304, episodic return=25.774118423461914\n",
      "global step=98304, episodic return=22.486209869384766\n",
      "global step=98304, episodic return=28.77623176574707\n",
      "global step=98304, episodic return=43.1009407043457\n",
      "global step=98304, episodic return=51.142784118652344\n",
      "global step=100352, episodic return=78.13427734375\n",
      "global step=100352, episodic return=22.737565994262695\n",
      "global step=100352, episodic return=58.27866744995117\n",
      "global step=100352, episodic return=41.52876281738281\n",
      "global step=100352, episodic return=43.32173156738281\n",
      "global step=100352, episodic return=26.8941593170166\n",
      "global step=100352, episodic return=53.100223541259766\n",
      "global step=100352, episodic return=54.47140121459961\n",
      "global step=100352, episodic return=34.54486083984375\n",
      "global step=100352, episodic return=59.398441314697266\n",
      "global step=100352, episodic return=37.37895965576172\n",
      "global step=100352, episodic return=29.154638290405273\n",
      "global step=100352, episodic return=42.468650817871094\n",
      "global step=100352, episodic return=61.307682037353516\n",
      "global step=100352, episodic return=59.97551345825195\n",
      "global step=102400, episodic return=57.38389587402344\n",
      "global step=102400, episodic return=33.59027099609375\n",
      "global step=102400, episodic return=36.80170822143555\n",
      "global step=102400, episodic return=38.724090576171875\n",
      "global step=102400, episodic return=60.548439025878906\n",
      "global step=102400, episodic return=53.688133239746094\n",
      "global step=102400, episodic return=25.358217239379883\n",
      "global step=102400, episodic return=39.019142150878906\n",
      "global step=102400, episodic return=45.022499084472656\n",
      "global step=102400, episodic return=33.27738952636719\n",
      "global step=102400, episodic return=61.37397766113281\n",
      "global step=102400, episodic return=79.3134994506836\n",
      "global step=102400, episodic return=29.51827049255371\n",
      "global step=102400, episodic return=41.441062927246094\n",
      "global step=102400, episodic return=43.71901321411133\n",
      "global step=102400, episodic return=45.24554443359375\n",
      "global step=102400, episodic return=73.48019409179688\n",
      "global step=102400, episodic return=57.25613784790039\n",
      "global step=102400, episodic return=71.03273010253906\n",
      "global step=102400, episodic return=42.984798431396484\n",
      "global step=102400, episodic return=34.417076110839844\n",
      "global step=102400, episodic return=30.98541831970215\n",
      "global step=102400, episodic return=35.72835159301758\n",
      "global step=102400, episodic return=40.65269088745117\n",
      "global step=102400, episodic return=31.653791427612305\n",
      "global step=104448, episodic return=15.040514945983887\n",
      "global step=104448, episodic return=35.575172424316406\n",
      "global step=104448, episodic return=51.80342102050781\n",
      "global step=104448, episodic return=64.26644897460938\n",
      "global step=104448, episodic return=29.531002044677734\n",
      "global step=104448, episodic return=57.549766540527344\n",
      "global step=104448, episodic return=33.905189514160156\n",
      "global step=104448, episodic return=84.65946197509766\n",
      "global step=104448, episodic return=30.230579376220703\n",
      "global step=104448, episodic return=32.23817443847656\n",
      "global step=104448, episodic return=58.36583709716797\n",
      "global step=104448, episodic return=31.22022247314453\n",
      "global step=104448, episodic return=32.348087310791016\n",
      "global step=104448, episodic return=31.49030303955078\n",
      "global step=104448, episodic return=47.16575241088867\n",
      "global step=106496, episodic return=45.26053237915039\n",
      "global step=106496, episodic return=28.51555633544922\n",
      "global step=106496, episodic return=48.10914611816406\n",
      "global step=106496, episodic return=41.912357330322266\n",
      "global step=106496, episodic return=49.30108642578125\n",
      "global step=106496, episodic return=22.99359703063965\n",
      "global step=106496, episodic return=59.07108688354492\n",
      "global step=108544, episodic return=66.38661193847656\n",
      "global step=108544, episodic return=55.92581558227539\n",
      "global step=108544, episodic return=53.46036148071289\n",
      "global step=108544, episodic return=61.65459060668945\n",
      "global step=108544, episodic return=64.90837860107422\n",
      "global step=108544, episodic return=42.589820861816406\n",
      "global step=108544, episodic return=85.58148956298828\n",
      "global step=108544, episodic return=49.33140563964844\n",
      "global step=110592, episodic return=63.90102767944336\n",
      "global step=110592, episodic return=43.088993072509766\n",
      "global step=110592, episodic return=46.21150588989258\n",
      "global step=110592, episodic return=53.36073303222656\n",
      "global step=110592, episodic return=44.33475112915039\n",
      "global step=110592, episodic return=52.80763626098633\n",
      "global step=110592, episodic return=62.238685607910156\n",
      "global step=110592, episodic return=53.747535705566406\n",
      "global step=110592, episodic return=36.25841522216797\n",
      "global step=110592, episodic return=48.243858337402344\n",
      "global step=110592, episodic return=65.6824951171875\n",
      "global step=110592, episodic return=45.65195846557617\n",
      "global step=110592, episodic return=79.86148834228516\n",
      "global step=110592, episodic return=51.31337356567383\n",
      "global step=110592, episodic return=48.117183685302734\n",
      "global step=112640, episodic return=59.07179260253906\n",
      "global step=112640, episodic return=49.60331344604492\n",
      "global step=112640, episodic return=61.69129943847656\n",
      "global step=112640, episodic return=56.160919189453125\n",
      "global step=112640, episodic return=63.727760314941406\n",
      "global step=112640, episodic return=42.1554069519043\n",
      "global step=112640, episodic return=54.857757568359375\n",
      "global step=112640, episodic return=40.888389587402344\n",
      "global step=112640, episodic return=54.18387222290039\n",
      "global step=114688, episodic return=28.96805763244629\n",
      "global step=114688, episodic return=30.729116439819336\n",
      "global step=114688, episodic return=39.28540802001953\n",
      "global step=114688, episodic return=68.50267028808594\n",
      "global step=114688, episodic return=43.5311279296875\n",
      "global step=114688, episodic return=49.88813781738281\n",
      "global step=114688, episodic return=34.595909118652344\n",
      "global step=114688, episodic return=45.93004608154297\n",
      "global step=114688, episodic return=46.13125228881836\n",
      "global step=116736, episodic return=31.98978042602539\n",
      "global step=116736, episodic return=40.3290901184082\n",
      "global step=116736, episodic return=45.07403564453125\n",
      "global step=116736, episodic return=33.441307067871094\n",
      "global step=116736, episodic return=82.82091522216797\n",
      "global step=116736, episodic return=57.22920227050781\n",
      "global step=116736, episodic return=58.81293487548828\n",
      "global step=116736, episodic return=33.29821014404297\n",
      "global step=116736, episodic return=33.338863372802734\n",
      "global step=116736, episodic return=49.65877151489258\n",
      "global step=116736, episodic return=67.68413543701172\n",
      "global step=118784, episodic return=47.55276870727539\n",
      "global step=118784, episodic return=63.6139030456543\n",
      "global step=118784, episodic return=11.745061874389648\n",
      "global step=118784, episodic return=34.539649963378906\n",
      "global step=118784, episodic return=39.36863708496094\n",
      "global step=118784, episodic return=42.40005874633789\n",
      "global step=118784, episodic return=22.257413864135742\n",
      "global step=118784, episodic return=65.19140625\n",
      "global step=118784, episodic return=39.74020767211914\n",
      "global step=120832, episodic return=43.50144577026367\n",
      "global step=120832, episodic return=67.8465347290039\n",
      "global step=120832, episodic return=41.80271911621094\n",
      "global step=120832, episodic return=81.65164184570312\n",
      "global step=120832, episodic return=59.517887115478516\n",
      "global step=120832, episodic return=65.6297607421875\n",
      "global step=120832, episodic return=73.1333999633789\n",
      "global step=120832, episodic return=24.535442352294922\n",
      "global step=120832, episodic return=50.2791862487793\n",
      "global step=120832, episodic return=67.98495483398438\n",
      "global step=120832, episodic return=68.85887908935547\n",
      "global step=120832, episodic return=23.35492515563965\n",
      "global step=120832, episodic return=56.723873138427734\n",
      "global step=120832, episodic return=87.90777587890625\n",
      "global step=120832, episodic return=41.03853225708008\n",
      "global step=120832, episodic return=22.9719181060791\n",
      "global step=122880, episodic return=37.430179595947266\n",
      "global step=122880, episodic return=97.4733657836914\n",
      "global step=122880, episodic return=32.55551528930664\n",
      "global step=122880, episodic return=22.76456069946289\n",
      "global step=122880, episodic return=35.197879791259766\n",
      "global step=122880, episodic return=84.96163940429688\n",
      "global step=122880, episodic return=55.96604537963867\n",
      "global step=122880, episodic return=41.21751022338867\n",
      "global step=124928, episodic return=69.79080200195312\n",
      "global step=124928, episodic return=33.402000427246094\n",
      "global step=124928, episodic return=77.2818374633789\n",
      "global step=124928, episodic return=28.401466369628906\n",
      "global step=124928, episodic return=45.49031448364258\n",
      "global step=124928, episodic return=24.395172119140625\n",
      "global step=124928, episodic return=18.092857360839844\n",
      "global step=124928, episodic return=39.68443298339844\n",
      "global step=124928, episodic return=43.41876220703125\n",
      "global step=124928, episodic return=46.58815002441406\n",
      "global step=126976, episodic return=52.68343734741211\n",
      "global step=126976, episodic return=37.5941047668457\n",
      "global step=126976, episodic return=52.86436462402344\n",
      "global step=126976, episodic return=42.40003204345703\n",
      "global step=126976, episodic return=40.2453498840332\n",
      "global step=126976, episodic return=52.409820556640625\n",
      "global step=126976, episodic return=39.49509811401367\n",
      "global step=126976, episodic return=50.858489990234375\n",
      "global step=129024, episodic return=49.026859283447266\n",
      "global step=129024, episodic return=53.34796905517578\n",
      "global step=129024, episodic return=70.02330780029297\n",
      "global step=131072, episodic return=55.559383392333984\n",
      "global step=131072, episodic return=100.89769744873047\n",
      "global step=131072, episodic return=75.68441772460938\n",
      "global step=131072, episodic return=52.503013610839844\n",
      "global step=131072, episodic return=90.7128677368164\n",
      "global step=131072, episodic return=31.501182556152344\n",
      "global step=131072, episodic return=30.319608688354492\n",
      "global step=133120, episodic return=95.95112609863281\n",
      "global step=133120, episodic return=94.93278503417969\n",
      "global step=133120, episodic return=68.91016387939453\n",
      "global step=133120, episodic return=74.28707122802734\n",
      "global step=135168, episodic return=23.317075729370117\n",
      "global step=135168, episodic return=43.166072845458984\n",
      "global step=135168, episodic return=47.08134841918945\n",
      "global step=137216, episodic return=51.875389099121094\n",
      "global step=137216, episodic return=54.39019775390625\n",
      "global step=137216, episodic return=104.24085235595703\n",
      "global step=137216, episodic return=33.99778747558594\n",
      "global step=137216, episodic return=72.30717468261719\n",
      "global step=137216, episodic return=47.556396484375\n",
      "global step=137216, episodic return=34.08698654174805\n",
      "global step=137216, episodic return=62.67984390258789\n",
      "global step=137216, episodic return=75.7156753540039\n",
      "global step=137216, episodic return=104.69820404052734\n",
      "global step=137216, episodic return=44.90779113769531\n",
      "global step=139264, episodic return=25.688945770263672\n",
      "global step=139264, episodic return=39.801673889160156\n",
      "global step=139264, episodic return=77.48406219482422\n",
      "global step=139264, episodic return=84.38284301757812\n",
      "global step=139264, episodic return=46.6199951171875\n",
      "global step=139264, episodic return=50.8534049987793\n",
      "global step=139264, episodic return=74.11205291748047\n",
      "global step=141312, episodic return=29.221288681030273\n",
      "global step=141312, episodic return=61.45952606201172\n",
      "global step=141312, episodic return=100.47705078125\n",
      "global step=141312, episodic return=98.91693115234375\n",
      "global step=141312, episodic return=54.9642333984375\n",
      "global step=141312, episodic return=35.87428665161133\n",
      "global step=141312, episodic return=51.30668640136719\n",
      "global step=141312, episodic return=24.8741512298584\n",
      "global step=143360, episodic return=57.2576789855957\n",
      "global step=143360, episodic return=39.22190856933594\n",
      "global step=143360, episodic return=78.38038635253906\n",
      "global step=143360, episodic return=105.62325286865234\n",
      "global step=143360, episodic return=55.04310607910156\n",
      "global step=143360, episodic return=50.3709831237793\n",
      "global step=143360, episodic return=44.67041015625\n",
      "global step=145408, episodic return=48.9276008605957\n",
      "global step=145408, episodic return=55.22955322265625\n",
      "global step=145408, episodic return=106.52737426757812\n",
      "global step=145408, episodic return=62.6414909362793\n",
      "global step=145408, episodic return=49.71236038208008\n",
      "global step=147456, episodic return=56.66529846191406\n",
      "global step=147456, episodic return=49.4905891418457\n",
      "global step=147456, episodic return=91.01139831542969\n",
      "global step=147456, episodic return=63.39998245239258\n",
      "global step=149504, episodic return=77.79020690917969\n",
      "global step=149504, episodic return=47.57953643798828\n",
      "global step=149504, episodic return=52.9448356628418\n",
      "global step=151552, episodic return=113.67410278320312\n",
      "global step=153600, episodic return=60.342071533203125\n",
      "global step=153600, episodic return=46.255760192871094\n",
      "global step=153600, episodic return=82.62842559814453\n",
      "global step=155648, episodic return=43.11782455444336\n",
      "global step=155648, episodic return=46.49392318725586\n",
      "global step=157696, episodic return=62.15093231201172\n",
      "global step=157696, episodic return=49.3020133972168\n",
      "global step=159744, episodic return=63.287254333496094\n",
      "global step=159744, episodic return=74.92025756835938\n",
      "global step=159744, episodic return=36.11582946777344\n",
      "global step=159744, episodic return=54.66436004638672\n",
      "global step=159744, episodic return=82.14376831054688\n",
      "global step=161792, episodic return=49.92498779296875\n",
      "global step=161792, episodic return=94.8862075805664\n",
      "global step=161792, episodic return=40.90411376953125\n",
      "global step=163840, episodic return=42.359352111816406\n",
      "global step=163840, episodic return=62.64625930786133\n",
      "global step=165888, episodic return=72.15341186523438\n",
      "global step=165888, episodic return=58.53368377685547\n",
      "global step=165888, episodic return=119.50389862060547\n",
      "global step=165888, episodic return=94.9222412109375\n",
      "global step=167936, episodic return=49.249855041503906\n",
      "global step=167936, episodic return=80.51699829101562\n",
      "global step=167936, episodic return=29.201261520385742\n",
      "global step=169984, episodic return=53.535011291503906\n",
      "global step=172032, episodic return=50.495399475097656\n",
      "global step=176128, episodic return=70.87451934814453\n",
      "global step=178176, episodic return=118.21025848388672\n",
      "global step=182272, episodic return=42.9427604675293\n",
      "global step=184320, episodic return=47.73396682739258\n",
      "global step=186368, episodic return=70.64232635498047\n",
      "global step=186368, episodic return=137.41256713867188\n",
      "global step=188416, episodic return=110.39761352539062\n",
      "global step=192512, episodic return=137.46240234375\n",
      "global step=196608, episodic return=113.82782745361328\n",
      "global step=206848, episodic return=77.69638061523438\n",
      "global step=208896, episodic return=99.4923324584961\n",
      "global step=212992, episodic return=83.90350341796875\n",
      "global step=217088, episodic return=82.32748413085938\n",
      "global step=245760, episodic return=169.11077880859375\n",
      "global step=403456, episodic return=242.86317443847656\n",
      "global step=493568, episodic return=308.6033630371094\n",
      "global step=548864, episodic return=361.2781982421875\n",
      "global step=567296, episodic return=351.52130126953125\n",
      "global step=608256, episodic return=389.86663818359375\n",
      "global step=610304, episodic return=384.5299377441406\n",
      "global step=622592, episodic return=389.0045471191406\n",
      "global step=657408, episodic return=409.2318115234375\n",
      "global step=679936, episodic return=424.1127624511719\n",
      "global step=692224, episodic return=409.6324157714844\n",
      "global step=696320, episodic return=386.3898620605469\n",
      "global step=702464, episodic return=411.5210876464844\n",
      "global step=716800, episodic return=444.8581848144531\n",
      "global step=727040, episodic return=392.4088439941406\n",
      "global step=739328, episodic return=421.2679443359375\n",
      "global step=743424, episodic return=419.9892883300781\n",
      "global step=747520, episodic return=440.99139404296875\n",
      "global step=753664, episodic return=459.5537109375\n",
      "global step=778240, episodic return=463.6506042480469\n",
      "global step=802816, episodic return=489.1902160644531\n",
      "global step=829440, episodic return=456.43170166015625\n",
      "global step=831488, episodic return=503.8086853027344\n",
      "global step=837632, episodic return=507.2135314941406\n",
      "global step=854016, episodic return=488.6862487792969\n",
      "global step=858112, episodic return=483.24176025390625\n",
      "global step=884736, episodic return=528.091064453125\n",
      "global step=890880, episodic return=502.3100280761719\n",
      "global step=901120, episodic return=512.9370727539062\n",
      "global step=911360, episodic return=532.7857055664062\n",
      "global step=917504, episodic return=533.8817749023438\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config = {\n",
    "        \"LR\": 3e-4,\n",
    "        \"NUM_ENVS\": 2048,\n",
    "        \"NUM_STEPS\": 10,\n",
    "        \"TOTAL_TIMESTEPS\": 1e6,\n",
    "        \"UPDATE_EPOCHS\": 4,\n",
    "        \"NUM_MINIBATCHES\": 32,\n",
    "        \"GAMMA\": 0.99,\n",
    "        \"GAE_LAMBDA\": 0.95,\n",
    "        \"CLIP_EPS\": 0.2,\n",
    "        \"ENT_COEF\": 0.0,\n",
    "        \"VF_COEF\": 0.5,\n",
    "        \"MAX_GRAD_NORM\": 0.5,\n",
    "        \"ACTIVATION\": \"tanh\",\n",
    "        \"ENV_NAME\": \"hopper\",\n",
    "        \"ANNEAL_LR\": False,\n",
    "        \"NORMALIZE_ENV\": True,\n",
    "        \"DEBUG\": True,\n",
    "    }\n",
    "    rng = jax.random.PRNGKey(30)\n",
    "    train_jit = jax.jit(make_train(config))\n",
    "    out = train_jit(rng)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
